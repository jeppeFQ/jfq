{
  "hash": "562c46d5ff92718090facfac3a2f1098",
  "result": {
    "engine": "knitr",
    "markdown": "\n### Hvad er NLP?\n\nNatural Language Processing (**NLP**) er et centralt felt indenfor **AI** (kunstig intellegens). Grundlæggende handler NLP om hvordan en computer kan forstå og fortolke *naturligt sprog*, dvs. menneskeligt talt sprog. Gerne opgaven er at maskiner kan bearbejde dette sprog (og endda kunne producere det).\n\nI dag spiller NLP en stor rolle i vores hverdag, da det påvirker den måde vi interagerer med teknologi og gør denne interaktion meget mere effektiv. Vi kan kun forvente at dette samspil, takket være NLP, fortsat blive mere effektivt og af større betydning i fremtiden.\n\n#### I kender allerede til NLP\n\nNLP er allerede dybt integreret i mange af de værktøjer og teknologier vi anvender eller bliver eksponeret til dagligt:\n\n- **Søgemaskinger**: Google (og konkurrenter) bruger NLP til at forstå de input og returnere det du faktisk efterspørger. Det er derfor søgemaskiner i dag kan \"overkomme\" stavefejl, synonymer, kontekst specikke forespørgsler, osv.\n\n- **Siri, Alexa, Google Assistant**: De lytter til os hele tiden, hvis først vi tænder for dem ...\n\n- **Oversættelser** (mellem menneskelige sprog): Services som Google Translate oversætter ikke bare ord-for-ord men forstår sig også på forskelle i syntaks, grammatik og (sproglige) kontekster og konventioner.\n\n- **Chatbots** ...\n\n- **Spamfiltrering**: Som vi kommer til at lære i dag.\n\n#### Et oversættelsesperspektiv\n\nComputeren forstår ikke sprog på samme måde som mennesker gør. De kan læse `1` og de kan læse `0`; men de kan sætte disse tegn sammen i uendelige rækker af varierende kompleksitet. Dvs. mønstre af binære numeriske inputs. NLP handler om at bygge bro mellem den måde, mennesker kommunikerer på, og hvordan maskiner forstår data.\n\n**En IKKE-UDTØMMENDE liste af grundlæggende elementer i oversættelse af naturligt sprog til maskin-læsbart sprog**:\n\n- ***Tokenization***, som handler om at dele en tekst op i mindre dele, ofte ord eller sætninger. En sætning som \"Jeg elsker data!\" blive delt op i tre(fire) tokens: [\"Jeg\", \"elsker\", \"data\", \"!\"].\n\n- **Stemming og Lemmatization**, som reducerer ord til deres grundform. Fx bliver \"løbende\" og \"løber\" reduceret til roden, \"løb\".\n\n- **Part-of-Speech Tagging** (POS Tagging), som identificerer ordklasser (som verber, substantiver osv.) for hvert ord i en sætning, hvilket gør det muligt at forstå ordenes funktion i sætningen.\n\n- **Named Entity Recognition** (NER), som identificerer navne på personer, steder eller organisationer i en tekst. For eksempel i sætningen \"Aalborg Universitet er et universitet i Danmark\" vil \"Aalborg Universitet\" blive genkendt som en organisation og \"Danmark\" som et land.\n\nDette oversættelsesperspektiv i en digital kontekst er centralt i dagens workshop.\n\n\n\n\n\n\n\n\n\n\n\n\n### Case: find Elon \n\n::: {.panel-tabset}\n\n## <i class=\"fa-brands fa-r-project\" style=\"color: #276DC3;\"></i> R packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidytext)\n```\n:::\n\n\n## <i class=\"fa-brands fa-python\" style=\"color: #3776AB;\"></i> Python \n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport session_info\n```\n:::\n\n\n:::\n\n::: {.panel-tabset}\n\n## <i class=\"fa-brands fa-r-project\" style=\"color: #276DC3;\"></i> R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressMessages(tweets <- vroom(\"find_elon\"))\n\nelon_tweet_df <- \n  tibble(tweets) %>% \n  rename(real = `1`,\n         text = `0`) %>% \n  mutate(real = as_factor(if_else(real == \"1\", \"real_elon\", \"fake_elon\"))) %>% \n  mutate(tweet_id = as_factor(row_number())) \n  \n\nelon_tweet_df %>% head(10) %>% gt()\n```\n:::\n\n\n## <i class=\"fa-brands fa-python\" style=\"color: #3776AB;\"></i> Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n1+1\n```\n:::\n\n\n## <i class=\"fa-solid fa-gears\"></i> `sessionInfo()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::session_info(pkgs = \"attached\", info = c(\"platform\", \"packages\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in info != \"auto\" && info != \"all\": 'length(x) = 2 > 1' in coercion to\n'logical(1)'\n\nWarning in info != \"auto\" && info != \"all\": 'length(x) = 2 > 1' in coercion to\n'logical(1)'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Copenhagen\n date     2024-11-04\n pandoc   3.3 @ /usr/local/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package  * version date (UTC) lib source\n tidytext * 0.4.2   2024-04-10 [1] CRAN (R 4.2.1)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nsession_info.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n-----\nnumpy               1.24.3\nsession_info        1.0.0\n-----\nPython 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:13:45) [Clang 14.0.6 ]\nmacOS-10.16-x86_64-i386-64bit\n-----\nSession information updated at 2024-11-04 13:56\n```\n\n\n:::\n:::\n\n\n:::\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}