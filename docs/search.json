[
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Jeppe F. Larsen",
    "section": "",
    "text": "Research Assistant, Aalborg University\nContact: Aalborg, Denmark | +45 30594555 | jeppe.fjeldgaard@gmail.com\n\n\n\nAs a researcher, I am passionate about utilizing register data and quantitative methods to investigate social and political phenomena. My expertise lies in effectively leveraging and managing Danish register data, as well as integrating external datasets such as survey or spatial data. Additionally, I have a strong interest in communicating quantitative findings through data visualization.\n\n\n\n\n\n\nAalborg University, Denmark\nFeb. 2021 — Jan. 2024\nThesis: Majority and Minority Exposure in Childhood – Studies of ethnic segregation in early life in Denmark and its consequences\n\n\n\nNIDI (Netherlands Interdisciplinary Demographic Institute)\nThe Hague, The Netherlands\nMar. 2023 – Sep. 2023\n\n\n\n\n\n\n\n\nEconomics (OECON), 2nd semester MSc\nAalborg University, Denmark\n2024 - Present\nPrincipal lecturer for a specialized course on Survival Analysis, using R.\n….\n\n\n\n\n\n\nR: 7 years\nPython: 3 years\nGeographical Information Systems (QGIS, ArcMap): 7 years\nRmarkdown/Quarto: 5 years\n\n\n\n\n\nCode-desk (2022-2023): CALSDISS, Aalborg University – Provided code-related assistance and feedback to students.\nStudent Assistant (2018-2020): Department of Politics and Society, Aalborg University.\n\n…"
  },
  {
    "objectID": "cv.html#additional-activities",
    "href": "cv.html#additional-activities",
    "title": "Jeppe F. Larsen",
    "section": "",
    "text": "Code-desk (2022-2023): CALSDISS, Aalborg University – Provided code-related assistance and feedback to students.\nStudent Assistant (2018-2020): Department of Politics and Society, Aalborg University.\n\n…"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jeppe Fjeldgaard Qvist",
    "section": "",
    "text": "Hello and welcome to my site. On this page, you can read about me; specifically my research interests and teaching profile. Other places on this website, you can read in more detail about my research."
  },
  {
    "objectID": "index.html#about-me-and-this-site",
    "href": "index.html#about-me-and-this-site",
    "title": "Jeppe Fjeldgaard Qvist",
    "section": "About me and this site",
    "text": "About me and this site\nLorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam pretium malesuada potenti commodo rutrum molestie tincidunt sodales. Risus nulla dui faucibus odio est phasellus tempus. Sollicitudin dapibus nunc ex congue nostra sapien velit. Praesent pellentesque vitae sociosqu orci magnis habitant maximus metus quisque. Velit tempus ad sodales hac; suspendisse suscipit.\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem. Himenaeos adipiscing ultrices ex; rutrum dignissim turpis. Libero sociosqu lacinia nibh; potenti elit viverra. Senectus fames fringilla praesent nascetur lacus lobortis dui tortor. Felis ridiculus lorem senectus convallis conubia nec phasellus nisi. Potenti sodales rhoncus et penatibus auctor morbi erat augue iaculis. Egestas dictumst phasellus class nec facilisis sapien lectus maximus iaculis. Quam nascetur fusce vivamus proin dolor; magna tempus curae."
  },
  {
    "objectID": "index.html#research-interests",
    "href": "index.html#research-interests",
    "title": "Jeppe Fjeldgaard Qvist",
    "section": "Research interests",
    "text": "Research interests\nLorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam pretium malesuada potenti commodo rutrum molestie tincidunt sodales. Risus nulla dui faucibus odio est phasellus tempus. Sollicitudin dapibus nunc ex congue nostra sapien velit. Praesent pellentesque vitae sociosqu orci magnis habitant maximus metus quisque. Velit tempus ad sodales hac; suspendisse suscipit.\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem. Himenaeos adipiscing ultrices ex; rutrum dignissim turpis. Libero sociosqu lacinia nibh; potenti elit viverra. Senectus fames fringilla praesent nascetur lacus lobortis dui tortor. Felis ridiculus lorem senectus convallis conubia nec phasellus nisi. Potenti sodales rhoncus et penatibus auctor morbi erat augue iaculis. Egestas dictumst phasellus class nec facilisis sapien lectus maximus iaculis. Quam nascetur fusce vivamus proin dolor; magna tempus curae."
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Jeppe Fjeldgaard Qvist",
    "section": "Teaching",
    "text": "Teaching\nLorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam pretium malesuada potenti commodo rutrum molestie tincidunt sodales. Risus nulla dui faucibus odio est phasellus tempus. Sollicitudin dapibus nunc ex congue nostra sapien velit. Praesent pellentesque vitae sociosqu orci magnis habitant maximus metus quisque. Velit tempus ad sodales hac; suspendisse suscipit.\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem. Himenaeos adipiscing ultrices ex; rutrum dignissim turpis. Libero sociosqu lacinia nibh; potenti elit viverra. Senectus fames fringilla praesent nascetur lacus lobortis dui tortor. Felis ridiculus lorem senectus convallis conubia nec phasellus nisi. Potenti sodales rhoncus et penatibus auctor morbi erat augue iaculis. Egestas dictumst phasellus class nec facilisis sapien lectus maximus iaculis. Quam nascetur fusce vivamus proin dolor; magna tempus curae."
  },
  {
    "objectID": "me.html",
    "href": "me.html",
    "title": "Om mig",
    "section": "",
    "text": "Hej! Jeg er [Dit Navn], og jeg arbejder som [Din Profession]. Jeg har en stærk interesse i [nøgleområde], og jeg er passioneret omkring [din arbejdsfilosofi eller værdier].\n\n\n\nProgrammeringssprog: Python, R, SQL\nVærktøjer: Git, Docker, Quarto\nEkspertiseområder: Dataanalyse, Datavisualisering, Softwareudvikling"
  },
  {
    "objectID": "me.html#erfaring-og-kompetencer",
    "href": "me.html#erfaring-og-kompetencer",
    "title": "Om mig",
    "section": "",
    "text": "Programmeringssprog: Python, R, SQL\nVærktøjer: Git, Docker, Quarto\nEkspertiseområder: Dataanalyse, Datavisualisering, Softwareudvikling"
  },
  {
    "objectID": "projects/project3.html",
    "href": "projects/project3.html",
    "title": "",
    "section": "",
    "text": "3+3\n\n[1] 6"
  },
  {
    "objectID": "projects/project3.html#ttt",
    "href": "projects/project3.html#ttt",
    "title": "",
    "section": "ttt",
    "text": "ttt"
  },
  {
    "objectID": "workshop.html#descriptive",
    "href": "workshop.html#descriptive",
    "title": "Workshops and teaching",
    "section": "Descriptive statistics [en]",
    "text": "Descriptive statistics [en]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\nLorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam pretium malesuada potenti commodo rutrum molestie tincidunt sodales. Risus nulla dui faucibus odio est phasellus tempus. Sollicitudin dapibus nunc ex congue nostra sapien velit. Praesent pellentesque vitae sociosqu orci magnis habitant maximus metus quisque. Velit tempus ad sodales hac; suspendisse suscipit.\n\n\n R packages\n Python imports\n\n\n\n\nlibrary(tidyverse)\n\n\n\n\nimport pandas as pd\nimport session_info\n\n\n\n\n\n\n R\n Python\n Session Info\n\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\n1+1\n\n\n\n\ndevtools::session_info(pkgs = \"attached\", info = c(\"platform\", \"packages\"))\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Copenhagen\n date     2024-12-04\n pandoc   3.3 @ /usr/local/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package   * version date (UTC) lib source\n dplyr     * 1.1.4   2023-11-17 [2] CRAN (R 4.2.0)\n forcats   * 1.0.0   2023-01-29 [2] CRAN (R 4.2.0)\n ggplot2   * 3.5.1   2024-04-23 [2] CRAN (R 4.2.1)\n lubridate * 1.9.3   2023-09-27 [2] CRAN (R 4.2.0)\n purrr     * 1.0.2   2023-08-10 [2] CRAN (R 4.2.0)\n readr     * 2.1.5   2024-01-10 [2] CRAN (R 4.2.1)\n stringr   * 1.5.1   2023-11-14 [2] CRAN (R 4.2.0)\n tibble    * 3.2.1   2023-03-20 [2] CRAN (R 4.2.0)\n tidyr     * 1.3.1   2024-01-24 [2] CRAN (R 4.2.1)\n tidyverse * 2.0.0   2023-02-22 [2] CRAN (R 4.2.0)\n\n [1] /Users/jeppefl/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\nsession_info.show()\n\n-----\npandas              2.0.3\nsession_info        1.0.0\n-----\nPython 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:13:45) [Clang 14.0.6 ]\nmacOS-10.16-x86_64-i386-64bit\n-----\nSession information updated at 2024-12-04 14:48"
  },
  {
    "objectID": "workshop.html#regression",
    "href": "workshop.html#regression",
    "title": "Workshops and teaching",
    "section": "Regression [en]",
    "text": "Regression [en]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\nRegression\n\nData …"
  },
  {
    "objectID": "workshop.html#segregation",
    "href": "workshop.html#segregation",
    "title": "Workshops and teaching",
    "section": "Segregation Indices [da]",
    "text": "Segregation Indices [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem."
  },
  {
    "objectID": "workshop.html#decomposition",
    "href": "workshop.html#decomposition",
    "title": "Workshops and teaching",
    "section": "Decomposition [en]",
    "text": "Decomposition [en]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\nDecomposition"
  },
  {
    "objectID": "workshop.html#sna",
    "href": "workshop.html#sna",
    "title": "Workshops and teaching",
    "section": "Network Analysis [en]",
    "text": "Network Analysis [en]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\nCase: Social networks\n\n\n R packages\n Python\n\n\n\n\nlibrary(tidyverse)\nlibrary(segregation)\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport session_info\n\n\n\n\n\n\n R\n Python\n Session Info\n\n\n\n\n1+1\n\n\n\n\nmat_friendship = pd.read_table(\"https://www.dropbox.com/s/0saiulir3pr566k/ELfriend.dat?dl=1\", delim_whitespace=True, header=None) \nmat_advice = pd.read_table(\"https://www.dropbox.com/s/apq42n1grim23k9/ELadv.dat?dl=1\", delim_whitespace=True, header=None) \nmat_work = pd.read_table(\"https://www.dropbox.com/s/dliz0sd7or8tv01/ELwork.dat?dl=1\", delim_whitespace=True, header=None)\n\n\n\n\ndevtools::session_info(pkgs = \"attached\", info = c(\"platform\", \"packages\"))\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Copenhagen\n date     2024-12-04\n pandoc   3.3 @ /usr/local/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.1.4   2023-11-17 [2] CRAN (R 4.2.0)\n forcats     * 1.0.0   2023-01-29 [2] CRAN (R 4.2.0)\n ggplot2     * 3.5.1   2024-04-23 [2] CRAN (R 4.2.1)\n lubridate   * 1.9.3   2023-09-27 [2] CRAN (R 4.2.0)\n purrr       * 1.0.2   2023-08-10 [2] CRAN (R 4.2.0)\n readr       * 2.1.5   2024-01-10 [2] CRAN (R 4.2.1)\n segregation * 1.1.0   2023-12-02 [2] CRAN (R 4.2.0)\n stringr     * 1.5.1   2023-11-14 [2] CRAN (R 4.2.0)\n tibble      * 3.2.1   2023-03-20 [2] CRAN (R 4.2.0)\n tidyr       * 1.3.1   2024-01-24 [2] CRAN (R 4.2.1)\n tidyverse   * 2.0.0   2023-02-22 [2] CRAN (R 4.2.0)\n\n [1] /Users/jeppefl/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\nsession_info.show()\n\n-----\nnumpy               1.24.3\npandas              2.0.3\nsession_info        1.0.0\n-----\nPython 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:13:45) [Clang 14.0.6 ]\nmacOS-10.16-x86_64-i386-64bit\n-----\nSession information updated at 2024-12-04 14:48\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Visualizing the stylized population network\n\n\n\n\n\nsee figure in full screen"
  },
  {
    "objectID": "workshop.html#spatial",
    "href": "workshop.html#spatial",
    "title": "Workshops and teaching",
    "section": "Spatial stuff: Mapping [en]",
    "text": "Spatial stuff: Mapping [en]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem."
  },
  {
    "objectID": "workshop.html#spatial-analysis",
    "href": "workshop.html#spatial-analysis",
    "title": "Workshops and teaching",
    "section": "Spatial stuff: Analysis [en]",
    "text": "Spatial stuff: Analysis [en]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem."
  },
  {
    "objectID": "workshop.html#sml",
    "href": "workshop.html#sml",
    "title": "Workshops and teaching",
    "section": "Supervised Machine Learning [en]",
    "text": "Supervised Machine Learning [en]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem."
  },
  {
    "objectID": "workshop.html#nlp",
    "href": "workshop.html#nlp",
    "title": "Workshops and teaching",
    "section": "Natural Language Processing [da]",
    "text": "Natural Language Processing [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\nHvad er NLP?\nNatural Language Processing (NLP) er et centralt felt indenfor AI (kunstig intellegens). Grundlæggende handler NLP om hvordan en computer kan forstå og fortolke naturligt sprog, dvs. menneskeligt talt sprog. Gerne opgaven er at maskiner kan bearbejde dette sprog (og endda kunne producere det).\nI dag spiller NLP en stor rolle i vores hverdag, da det påvirker den måde vi interagerer med teknologi og gør denne interaktion meget mere effektiv. Vi kan kun forvente at dette samspil, takket være NLP, fortsat blive mere effektivt og af større betydning i fremtiden.\nI kender allerede til NLP\nNLP er allerede dybt integreret i mange af de værktøjer og teknologier vi anvender eller bliver eksponeret til dagligt:\n\nSøgemaskinger: Google (og konkurrenter) bruger NLP til at forstå de input og returnere det du faktisk efterspørger. Det er derfor søgemaskiner i dag kan “overkomme” stavefejl, synonymer, kontekst specikke forespørgsler, osv.\nSiri, Alexa, Google Assistant: De lytter til os hele tiden, hvis først vi tænder for dem …\nOversættelser (mellem menneskelige sprog): Services som Google Translate oversætter ikke bare ord-for-ord men forstår sig også på forskelle i syntaks, grammatik og (sproglige) kontekster og konventioner.\nChatbots …\nSpamfiltrering: Som vi kommer til at lære i dag.\nEt oversættelsesperspektiv\nComputeren forstår ikke sprog på samme måde som mennesker gør. De kan læse 1 og de kan læse 0; men de kan sætte disse tegn sammen i uendelige rækker af varierende kompleksitet. Dvs. mønstre af binære numeriske inputs. NLP handler om at bygge bro mellem den måde, mennesker kommunikerer på, og hvordan maskiner forstår data.\nEn IKKE-UDTØMMENDE liste af grundlæggende elementer i oversættelse af naturligt sprog til maskin-læsbart sprog:\n\nTokenization, som handler om at dele en tekst op i mindre dele, ofte ord eller sætninger. En sætning som “Jeg elsker data!” blive delt op i tre(fire) tokens: [“Jeg”, “elsker”, “data”, “!”].\nStemming og Lemmatization, som reducerer ord til deres grundform. Fx bliver “løbende” og “løber” reduceret til roden, “løb”.\nPart-of-Speech Tagging (POS Tagging), som identificerer ordklasser (som verber, substantiver osv.) for hvert ord i en sætning, hvilket gør det muligt at forstå ordenes funktion i sætningen.\nNamed Entity Recognition (NER), som identificerer navne på personer, steder eller organisationer i en tekst. For eksempel i sætningen “Aalborg Universitet er et universitet i Danmark” vil “Aalborg Universitet” blive genkendt som en organisation og “Danmark” som et land.\n\nDette oversættelsesperspektiv i en digital kontekst er centralt i dagens workshop.\nCase: find Elon\n\n\n R packages\n Python\n\n\n\n\nlibrary(tidytext)\n\n\n\n\nimport numpy as np\nimport session_info\n\n\n\n\n\n\n R\n Python\n sessionInfo()\n\n\n\n\nsuppressMessages(tweets &lt;- vroom(\"find_elon\"))\n\nelon_tweet_df &lt;- \n  tibble(tweets) %&gt;% \n  rename(real = `1`,\n         text = `0`) %&gt;% \n  mutate(real = as_factor(if_else(real == \"1\", \"real_elon\", \"fake_elon\"))) %&gt;% \n  mutate(tweet_id = as_factor(row_number())) \n  \n\nelon_tweet_df %&gt;% head(10) %&gt;% gt()\n\n\n\n\n1+1\n\n\n\n\ndevtools::session_info(pkgs = \"attached\", info = c(\"platform\", \"packages\"))\n\nWarning in info != \"auto\" && info != \"all\": 'length(x) = 2 &gt; 1' in coercion to\n'logical(1)'\n\nWarning in info != \"auto\" && info != \"all\": 'length(x) = 2 &gt; 1' in coercion to\n'logical(1)'\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Copenhagen\n date     2024-12-04\n pandoc   3.3 @ /usr/local/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.1.4   2023-11-17 [2] CRAN (R 4.2.0)\n forcats     * 1.0.0   2023-01-29 [2] CRAN (R 4.2.0)\n ggplot2     * 3.5.1   2024-04-23 [2] CRAN (R 4.2.1)\n lubridate   * 1.9.3   2023-09-27 [2] CRAN (R 4.2.0)\n purrr       * 1.0.2   2023-08-10 [2] CRAN (R 4.2.0)\n readr       * 2.1.5   2024-01-10 [2] CRAN (R 4.2.1)\n segregation * 1.1.0   2023-12-02 [2] CRAN (R 4.2.0)\n stringr     * 1.5.1   2023-11-14 [2] CRAN (R 4.2.0)\n tibble      * 3.2.1   2023-03-20 [2] CRAN (R 4.2.0)\n tidyr       * 1.3.1   2024-01-24 [2] CRAN (R 4.2.1)\n tidytext    * 0.4.2   2024-04-10 [2] CRAN (R 4.2.1)\n tidyverse   * 2.0.0   2023-02-22 [2] CRAN (R 4.2.0)\n\n [1] /Users/jeppefl/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\nsession_info.show()\n\n-----\nnumpy               1.24.3\npandas              2.0.3\nsession_info        1.0.0\n-----\nPython 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:13:45) [Clang 14.0.6 ]\nmacOS-10.16-x86_64-i386-64bit\n-----\nSession information updated at 2024-12-04 14:48"
  },
  {
    "objectID": "workshop.html#nb",
    "href": "workshop.html#nb",
    "title": "Workshops and teaching",
    "section": "Naive Bayes [da]",
    "text": "Naive Bayes [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\nCase …\nSuperviseret Machine Learning (SML)\nI dag er fokus kun på superviseret ML, da vi kun har en enkelt workshop i dag og der vil være for mange statistiske forudsætninger til de to andre hovedtyper.\nSML fungerer ved, at vi giver modellen data, hvor vi kender det rigtige svar. Det kunne være, om en besked er spam eller ej, om et produkt er populær baseret på salgsdata, eller hvilken temperatur der vil være i morgen baseret på historiske målinger.\n\nI besked-eksemplet vil det altså sige at vi har et datasæt bestående af SMSer, hvor hver SMS i den data vi træner vores model på er kodet, dvs. tilskrevet et label, der indikerer om SMSen er spam (label=1) eller ikke-spam – “ham” – (label=0).\n\nModellen lærer sammenhænge mellem de inputdata (features, ord), som vi fodrer den med, og de kendte svar (labels, spam/ham). Når modellen er trænet, og den er vurderet til at være god nok, kan vi bruge den til at forudsige labels for nye data, hvor vi ikke kender svaret på forhånd.\nDet største problem i at arbejde med tekst i ML er at ML-algoritme ikke kan arbejde direkte med tekst. De kræver numeriske inputs for at kunne udføre matematiske operationer (se grundbog).\nVi er altså nødt til at konvertere tekst til en numerisk repræsentation. I denne kontekst kaldes denne proces for vectorisering.\nI denne proces transformerer og repræsenterer vi hvert tekstdokument (fx en SMS) som en række tal eller en vektor.\nKlassifikationsalgoritme\nNaive Bayes er en algoritme til at løse et konkret klassifikationsproblem relateret til naturligt sprog\nNaive Bayes er en probabilistisk klassifikationsmodel, baseret på Bayes’ teorem. Algoritmen fungerer ved at beregne sandsynligheden for, at en besked tilhører en bestemt klasse, givet dens indhold (dvs. de ord, der optræder i beskeden).\nModellen kaldes for “Naiv” grundet en central antagelse om at alle features (i vores tilfælde ord) er uafhængige af hinanden. Denne antagelse er ikke realistisk, da ord normalt ikke optræder helt uafhængigt af hinanden (ord i sætninger er ofte afhængige af hinanden). Det gør algoritmen enkel og hurtig, og den fungerer alligevel godt i praksis, som er blevet illustreret i tekniske detaljer mange steder.\nModellens formål er at lære forholdet mellem de inputdata, vi giver den (features), og de kendte labels, så den kan forudsige labels for nye, ukendte data.\nDet vil altså sige at vi har med et klassifikationsproblem at gøre. Modellen skal forudsige, hvilken kategori noget tilhører, og virke som et spam-filter, hvor vi klassificerer beskeder som enten “spam” eller “ikke-spam”, og i en praktisk applikation kan sende indkomne beskeder ind i forskellige mapper, som I kender fra jeres e-mail.\nBayes’ Teorem\nBayes’ Theorem handler om at beregne betingede sandsynligheder, der giver os en måde at opdatere vores viden baseret på nye data. Det har givet navn til en hel gren i statistikke, bayesisk statistik, som står i kontrast til frekvensstatistik (som er det i med al sandsynlighed kender fra gymnasiet og det i skal lære på 4. semester).\nBayes’ teorem er givet ved:\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\nHvor,\n\n\nP(A∣B): Sandsynligheden for A, givet B. Dette kalder vi den posterior sandsynligheden.\n\nP(B∣A): Sandsynligheden for B, givet A. Dette kalder vi likelihood (betinget sandsynlighed).\n\nP(A): Sandsynligheden for A uden at tage hensyn til B. Dette kalder vi prior sandsynligheden.\n\nP(B): Sandsynligheden for B, uanset hvad A er.\n\nI kontekst og i en klassifikationssammenhæng er:\n\n\nA klassen (spam eller ham), og\n\nB er de observerede data (de ord, der optræder i beskeden).\n\nog det vi er interesserde i er at bestemme P(spam∣ord): sandsynligheden for, at en besked er spam, givet at visse ord optræder.\nRepitation af formål og hvad vi vil implementere i Python er:\n\nSandsynligheden for at en SMS er spam, baseret på fremkomsten/tilstedeværelsen af et givent ord, er proportionelt til sandsynligheden for at ordet fremkommer i spam-SMSer og den a priori sandsynlighed for at en tilfældig SMS er spam.\n\n\nP(\\text{spam}|ord)\\propto P(ord|\\text{spam}) P(\\text{spam})\n\n\nSpg.: Hvordan implimenterer vi denne model i Python på en måde, der kan “lære” maskinen at genkende spam-SMSer?\n\nAnvendelse af algoritmen til tekstklassificering\nVi bruger Naive Bayes til tekstklassifikation for at forudsige om en besked er spam eller ham baseret på sandsynligheden for de enkelte ord, der optræder i beskeden, tilhører en given klasse.\nDen generelle Naive Bayes-klassifikator for to klasser (spam eller ikke-spam) er formuleret som:\n \\hat{y} = \\underset{c}{\\operatorname{argmax}} \\ P(c) \\prod_{i=1}^{n} P(x_i | c) \nHvor,\n\n\n\\hat{y} er den forudsagte klasse.\n\nc er en af klasserne (spam eller ikke-spam).\n\nP(c) er prior sandsynligheden for klassen c (sandsynligheden for, at en tilfældig besked er spam).\n\nP(x_{i}∣c) er sandsynligheden for ordet x_{i}, givet klassen c.\n\nn er antallet af ord i beskeden.\n\nMed formlen beregner vi sandsynligheden for, at en besked tilhører hver klasse (spam eller ikke-spam), og vælger den klasse, der har den højeste sandsynlighed: Vi vælger den klasse (c), hvor P(c|x) er størst, indikeret i formlen med \\underset{c}{\\operatorname{argmax}}\nFremgangsmåde:\n\nPrior sandsynlighed, P(c), beregnes ved at tælle, hvor mange af vores træningsbeskeder, der er spam i forhold til det samlede antal beskeder: P(spam)= \\frac{\\text{Antal spam-beskeder}}{\\text{Totalt antal beskeder}}\nLikelihood (betinget sandsynlighed), P(x_{i}∣c) beregnes som: P(x_{i}∣spam)= \\frac{\\text{Antal spam-beskeder, der indeholder } x_{i}}{\\text{Antal spam-beskeder totalt}}\n\nHvad vi er udregner, er hvor ofte hvert unikke ord i vores SAMLEDE TEKSTMATERIALE optræder i spam-beskeder (eller ikke-spam-beskeder), og produktet af sandsynlighederne for hvert enkelt ord i en given tekst, definere om teksten sandsynligvis er spam (eller ikke-spam)\nSelvom algoritmen er “naiv” og antagelsen om at alle ord er uafhængige, i praksis som udgangspunkt ikke holder, bestemmer vi stadig sandsynligheden for om en besked er spam eller ham som produktet af sandsynlighederne for de enkelte ord. Det er mange gange vist at denne “fejlantagelse” ikke er et problem i større mængder tekstdata.\n\nVi bruger træningsdata til at beregne P(spam) og P(ham)\n\nVi beregner sandsynlighederne for ordene “Congratulations”, “won”, “free”, osv. under begge klasser (spam og ham). Altså, hvad er sandsynligheden for at “free” (x_{free}) tilhører hhv. spam og ham klassen, givet fremkomsten af x_{free} i SMSer klassificeret som spam eller ham.\nVi multiplicerer sandsynlighederne for de enkelte ord – $x_{Congratulation} + x_{won} + x_{free} + $ – og vælger den klasse med den højeste sandsynlighed. Altså, hvert ord i en SMS har en sandsynlighed for at tilhører spam eller ham, og givet disse enkelte ord, hvor sandsynligt er det så for at SMS i sin helhed er spam eller ham.\n\nAltså, hvis ord som “won” og “free” ofte forekommer i spam-beskeder, vil Naive Bayes tildele beskeder med (store) fremkomster af disse ord en høj sandsynlighed for at være spam, og med denne sandsynlighedsargumentation klassificere SMSen som spam.\nEn lille, men central, sidebemærkning…\nDer kan opstå en problematisk udfordring, hvis et ord i udenfor vores træningsdata ikke fremgår i træningsdataen, da det vil “nulstille” den samlede sandsynlighed når vi multiplicerer.\nDette overkommes ved at inkludere en metode, der kaldes Laplace-smoothing, hvor alle betingede sandsynligheder tilføjes en lille konstant (værdi), således at ingen sandsynligheder er 0:\nP(x_{i}∣c)= \\frac{\\text{Totalt antal ord i klassen }+V}{\\text{Antal gange ordet optræder i klassen} +1}\nHvor, V er størrelsen af ordforrådet i vores corpus (antallet af unikke ord i træningsdataene). Med dette undgår vi nul-sandsynligheder.\nModel-træning\n\nI arbejdet med superviseret Machine Learning arbejder vi med vores data som opdelt i hhv. trænings- og testdata. Den data vi arbejder med, er et datasæt som vi har kvalitativt kodet med de korrekte labels ud fra vores forhåndsviden. Med denne opdeling er det muligt både at træne vores model og evaluere vores model, for at kunne vurdere hvordan modellen performer på nye, usete data.\n\nTræningsdata\nTræningsdataen er det datasæt, som vi træner vores model på. Datasættet indeholder både features (ord) og labels (korrekte kategorier). Det vil sige, vi ved altså hvad den rigtige kategori til vores tekster er, for at vores model at udregne det mønster, der kendetegner hver kategori.\nMed andre ord, når vi træner en Naive Bayes-model, “lærer” den at forstå sammenhængen mellem de input og de tilknyttede labels.\nEn klassisk opdeling er, at træningsdataen udgør 80% af den kvalitativt kodet data.\n\nTestdata\nTestdata udgør den anden del af den kvalitativt kodede data (her 20%). Testdataene bruges til at evaluere modelens præstation og generaliseringsevne og formålet med testdata er at give et mål for, hvordan modellen vil præstere på nye, usete data. Det vil altså sige at modellen ikke har “set” denne data (og er grunden til at vi skal have Laplace Smoothing…)\nEksempel …\nKlargøring af tekstdata\nDer er flere måde, hvorpå vi kan vektoriserer tekster, men centrale of typiske i denne form for analyse er:\n\nBag of Words (BoW)\nTF-IDF (Term Frequency-Inverse Document Frequency)\n\nBoW\nBag of Words er den mest simpel metode til at transformere tekst til numerisk form. Det fungerer ved at tælle, hvor mange gange hvert ord forekommer i et dokument, uden at tage højde for ordets rækkefølge eller kontekst. Resultatet er en vektor, der repræsenterer frekvensen af hvert ord i dokumentet. Eksempel på BoW:\nTekst 1: Jeg elsker spam\nTekst 2: Jeg kan ikke fordrage spam\nFørst opretter vi et ordforråd (vocabulary) baseret på alle de unikke ord i vores dokumenter:\n\n\nR\nPython\nsessionInfo\n\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\nvocab = ['Jeg', 'elsker', 'spam', 'kan', 'ikke', 'fordrage']\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidytext_0.4.2    segregation_1.1.0 lubridate_1.9.3   forcats_1.0.0    \n [5] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n [9] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11        here_1.0.1         lattice_0.22-5     png_0.1-8         \n [5] rprojroot_2.0.4    digest_0.6.33      utf8_1.2.4         mime_0.12         \n [9] R6_2.5.1           evaluate_1.0.1     pillar_1.9.0       rlang_1.1.2       \n[13] data.table_1.15.0  miniUI_0.1.1.1     urlchecker_1.0.1   Matrix_1.5-3      \n[17] reticulate_1.34.0  rmarkdown_2.28     devtools_2.4.5     RcppProgress_0.4.2\n[21] htmlwidgets_1.6.4  munsell_0.5.1      shiny_1.8.0        janeaustenr_1.0.0 \n[25] compiler_4.2.1     httpuv_1.6.14      xfun_0.41          pkgconfig_2.0.3   \n[29] pkgbuild_1.4.3     htmltools_0.5.7    tidyselect_1.2.0   fansi_1.0.6       \n[33] tzdb_0.4.0         withr_3.0.2        later_1.3.2        SnowballC_0.7.1   \n[37] grid_4.2.1         jsonlite_1.8.8     xtable_1.8-4       gtable_0.3.6      \n[41] lifecycle_1.0.4    magrittr_2.0.3     tokenizers_0.3.0   scales_1.3.0      \n[45] cli_3.6.2          stringi_1.8.3      cachem_1.0.8       fs_1.6.3          \n[49] promises_1.2.1     remotes_2.4.2.1    ellipsis_0.3.2     generics_0.1.3    \n[53] vctrs_0.6.5        tools_4.2.1        glue_1.6.2         hms_1.1.3         \n[57] pkgload_1.3.4      fastmap_1.1.1      yaml_2.3.8         timechange_0.3.0  \n[61] colorspace_2.1-0   sessioninfo_1.2.2  memoise_2.0.1      knitr_1.45        \n[65] usethis_2.2.3      profvis_0.3.8     \n\n\n\n\n\nffffffffffff\n\n\nR\nPython\nsessionInfo\n\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\ntekst1 = [1, 1, 1, 0, 0, 0]\ntekst2 = [1, 0, 1, 1, 1, 1]\ndf = pd.DataFrame([tekst1, tekst2], columns=vocab, index=['tekst1', 'tekst2'])\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidytext_0.4.2    segregation_1.1.0 lubridate_1.9.3   forcats_1.0.0    \n [5] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n [9] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11        here_1.0.1         lattice_0.22-5     png_0.1-8         \n [5] rprojroot_2.0.4    digest_0.6.33      utf8_1.2.4         mime_0.12         \n [9] R6_2.5.1           evaluate_1.0.1     pillar_1.9.0       rlang_1.1.2       \n[13] data.table_1.15.0  miniUI_0.1.1.1     urlchecker_1.0.1   Matrix_1.5-3      \n[17] reticulate_1.34.0  rmarkdown_2.28     devtools_2.4.5     RcppProgress_0.4.2\n[21] htmlwidgets_1.6.4  munsell_0.5.1      shiny_1.8.0        janeaustenr_1.0.0 \n[25] compiler_4.2.1     httpuv_1.6.14      xfun_0.41          pkgconfig_2.0.3   \n[29] pkgbuild_1.4.3     htmltools_0.5.7    tidyselect_1.2.0   fansi_1.0.6       \n[33] tzdb_0.4.0         withr_3.0.2        later_1.3.2        SnowballC_0.7.1   \n[37] grid_4.2.1         jsonlite_1.8.8     xtable_1.8-4       gtable_0.3.6      \n[41] lifecycle_1.0.4    magrittr_2.0.3     tokenizers_0.3.0   scales_1.3.0      \n[45] cli_3.6.2          stringi_1.8.3      cachem_1.0.8       fs_1.6.3          \n[49] promises_1.2.1     remotes_2.4.2.1    ellipsis_0.3.2     generics_0.1.3    \n[53] vctrs_0.6.5        tools_4.2.1        glue_1.6.2         hms_1.1.3         \n[57] pkgload_1.3.4      fastmap_1.1.1      yaml_2.3.8         timechange_0.3.0  \n[61] colorspace_2.1-0   sessioninfo_1.2.2  memoise_2.0.1      knitr_1.45        \n[65] usethis_2.2.3      profvis_0.3.8     \n\n\n\n\n\nffffffffffff\nTF-IDF\nTF-IDF tager, i modsætning til BoW, højde for, hvor ofte et ord forekommer i en tekst, i forhold til hvor ofte det forekommer i hele datasættet. Dette hjælper med at nedvægte meget almindelige ord (såsom “is”, “am,”the”, osv.), som sandsynligvis ikke bidrager meget til meningen af dokumentet, og fremhæve ord, der er særligt vigtige for den specifikke besked (såsom “free”, “won”).\nTF-IDF for et ord x i et dokument d er givet ved:\n\\text{TF-IDF}(x,d)=\\text{TF}(x,d) \\times \\text{IDF}(x)\nHvor:\n\nTF (Term Frequency): Måler hvor ofte ordet x forekommer i dokumentet d.\nIDF (Inverse Document Frequency): log ⁡\\left( \\frac{N}{df(x)} \\right ), hvor N er det totale antal dokumenter, og df(x) er antallet af dokumenter, som indeholder x.\n\nHermed sikrer vi at vi ikke vægter almindelige ord for højt, men i stedet fokuserer på de vigtigere ord.\n\n\nR\nPython\nsessionInfo\n\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\ncorpus = [\"Jeg elsker spam\",\"Jeg kan ikke fordrage spam\"]\n\ndf = pd.DataFrame({'dokument': corpus})\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidytext_0.4.2    segregation_1.1.0 lubridate_1.9.3   forcats_1.0.0    \n [5] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n [9] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11        here_1.0.1         lattice_0.22-5     png_0.1-8         \n [5] rprojroot_2.0.4    digest_0.6.33      utf8_1.2.4         mime_0.12         \n [9] R6_2.5.1           evaluate_1.0.1     pillar_1.9.0       rlang_1.1.2       \n[13] data.table_1.15.0  miniUI_0.1.1.1     urlchecker_1.0.1   Matrix_1.5-3      \n[17] reticulate_1.34.0  rmarkdown_2.28     devtools_2.4.5     RcppProgress_0.4.2\n[21] htmlwidgets_1.6.4  munsell_0.5.1      shiny_1.8.0        janeaustenr_1.0.0 \n[25] compiler_4.2.1     httpuv_1.6.14      xfun_0.41          pkgconfig_2.0.3   \n[29] pkgbuild_1.4.3     htmltools_0.5.7    tidyselect_1.2.0   fansi_1.0.6       \n[33] tzdb_0.4.0         withr_3.0.2        later_1.3.2        SnowballC_0.7.1   \n[37] grid_4.2.1         jsonlite_1.8.8     xtable_1.8-4       gtable_0.3.6      \n[41] lifecycle_1.0.4    magrittr_2.0.3     tokenizers_0.3.0   scales_1.3.0      \n[45] cli_3.6.2          stringi_1.8.3      cachem_1.0.8       fs_1.6.3          \n[49] promises_1.2.1     remotes_2.4.2.1    ellipsis_0.3.2     generics_0.1.3    \n[53] vctrs_0.6.5        tools_4.2.1        glue_1.6.2         hms_1.1.3         \n[57] pkgload_1.3.4      fastmap_1.1.1      yaml_2.3.8         timechange_0.3.0  \n[61] colorspace_2.1-0   sessioninfo_1.2.2  memoise_2.0.1      knitr_1.45        \n[65] usethis_2.2.3      profvis_0.3.8     \n\n\n\n\n\nffffffffffff\n\n\nR\nPython\nsessionInfo\n\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\n# Beregn TF for hvert ord i dokumentet:\n\n# Tokenisere dokumenter:\n# hvad kalder vi det når vi skriver .apply(lambda x: ...)?\n# og hvad sker der?\ndf['tokens'] = df['dokument'].apply(lambda x: x.split())\n\n# Beregn antallet af ord i hvert dokument\n# Hvad sker der her?\ndf['total_ord'] = df['tokens'].apply(len)\n\n# En liste af alle tokens:\n# 1. Vi looper først over hver sublist i df['tokens'], der er alle ord i en tekst. Dvs. vi looper over hver række i kolonnen 'tokens'.\n# 2. Når vi har en specifik sublist, \"liste_med_ord\", looper vi nu over hvert enkelt token (ord, x) i denne subliste.\n# 3. For hvert token i hver sublist, føjes dette token til den nye liste alle_tokens med .append().\nalle_tokens = []\nfor liste_med_ord in df['tokens']:\n    for x in liste_med_ord:\n        alle_tokens.append(x)\n\n# Find de unikke tokens:\n# \"set()\" funktion er kun at gemme unikke elementer/værdier\n# \"sorted()\" er med for at organisere vores tokens alfabetisk, men er som sådan ikke nødvendig. Prøv evt. uden.\nunikke_tokens = sorted(set(alle_tokens))\n\n# Udregn TF for hvert dokument for hvert ord\nfor ord in unikke_tokens:\n    df[ord] = df['tokens'].apply(lambda x: x.count(ord) / len(x))\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidytext_0.4.2    segregation_1.1.0 lubridate_1.9.3   forcats_1.0.0    \n [5] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n [9] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11        here_1.0.1         lattice_0.22-5     png_0.1-8         \n [5] rprojroot_2.0.4    digest_0.6.33      utf8_1.2.4         mime_0.12         \n [9] R6_2.5.1           evaluate_1.0.1     pillar_1.9.0       rlang_1.1.2       \n[13] data.table_1.15.0  miniUI_0.1.1.1     urlchecker_1.0.1   Matrix_1.5-3      \n[17] reticulate_1.34.0  rmarkdown_2.28     devtools_2.4.5     RcppProgress_0.4.2\n[21] htmlwidgets_1.6.4  munsell_0.5.1      shiny_1.8.0        janeaustenr_1.0.0 \n[25] compiler_4.2.1     httpuv_1.6.14      xfun_0.41          pkgconfig_2.0.3   \n[29] pkgbuild_1.4.3     htmltools_0.5.7    tidyselect_1.2.0   fansi_1.0.6       \n[33] tzdb_0.4.0         withr_3.0.2        later_1.3.2        SnowballC_0.7.1   \n[37] grid_4.2.1         jsonlite_1.8.8     xtable_1.8-4       gtable_0.3.6      \n[41] lifecycle_1.0.4    magrittr_2.0.3     tokenizers_0.3.0   scales_1.3.0      \n[45] cli_3.6.2          stringi_1.8.3      cachem_1.0.8       fs_1.6.3          \n[49] promises_1.2.1     remotes_2.4.2.1    ellipsis_0.3.2     generics_0.1.3    \n[53] vctrs_0.6.5        tools_4.2.1        glue_1.6.2         hms_1.1.3         \n[57] pkgload_1.3.4      fastmap_1.1.1      yaml_2.3.8         timechange_0.3.0  \n[61] colorspace_2.1-0   sessioninfo_1.2.2  memoise_2.0.1      knitr_1.45        \n[65] usethis_2.2.3      profvis_0.3.8     \n\n\n\n\n\nfffffffffff\n\n\nR\nPython\nsessionInfo\n\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\n# Beregn IDF for hvert ord i dokumentet:\n\nimport math # For at få log()-funktionen\n\n# Beregne IDF for hvert ord\n# 1. Definer funktion\ndef bestem_idf(ord, df):\n    # Antal dokumenter der indeholder ordet\n    # 2.: df['tokens'] er en kollonne i vores DataFrame (df)\n    # 3.: .apply(lambda x: ord in x) for hvert dokument (SMS),\n    #     repræsenteret som en liste af ord, tjekker vi om ordet er til stede\n    #     i dokumentet. Funktionen returnerer TRUE eller FALSE (ord in x: True or False?)\n    # 4.: TRUE og FALSE repræsenteres nummerisk som 1 og 0. Ved at summere alle 1ere og 0ere,\n    #     får vi antallet af dokumenter, der indeholder ord x.\n    doks_med_ord = df['tokens'].apply(lambda x: ord in x).sum()\n    # Beregn IDF\n    # 5.: len() giver en værdi for antallet af dokumenter (SMSer). Tælleren i formlen.\n    #     (1 + doks_med_ord) er nævneren i formlen\n    #     .log(...) tager logaritmen.\n    return math.log(len(df) / (1 + doks_med_ord))\n\n# Beregn IDF for hvert unikke ord\n    # 6. Dette kalder vi en \"dictionary comprehension\", fordi koden her går\n    #    gennem alle ord i unikke_tokens og for HVERT ORD i unikke_tokens\n    #    kaldes vores definerede funktion \"bestem_idf\" og tilknytter en IDF-score\n    #    til dette ord.\nidf_scores = {ord: bestem_idf(ord, df) for ord in unikke_tokens}\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidytext_0.4.2    segregation_1.1.0 lubridate_1.9.3   forcats_1.0.0    \n [5] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n [9] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11        here_1.0.1         lattice_0.22-5     png_0.1-8         \n [5] rprojroot_2.0.4    digest_0.6.33      utf8_1.2.4         mime_0.12         \n [9] R6_2.5.1           evaluate_1.0.1     pillar_1.9.0       rlang_1.1.2       \n[13] data.table_1.15.0  miniUI_0.1.1.1     urlchecker_1.0.1   Matrix_1.5-3      \n[17] reticulate_1.34.0  rmarkdown_2.28     devtools_2.4.5     RcppProgress_0.4.2\n[21] htmlwidgets_1.6.4  munsell_0.5.1      shiny_1.8.0        janeaustenr_1.0.0 \n[25] compiler_4.2.1     httpuv_1.6.14      xfun_0.41          pkgconfig_2.0.3   \n[29] pkgbuild_1.4.3     htmltools_0.5.7    tidyselect_1.2.0   fansi_1.0.6       \n[33] tzdb_0.4.0         withr_3.0.2        later_1.3.2        SnowballC_0.7.1   \n[37] grid_4.2.1         jsonlite_1.8.8     xtable_1.8-4       gtable_0.3.6      \n[41] lifecycle_1.0.4    magrittr_2.0.3     tokenizers_0.3.0   scales_1.3.0      \n[45] cli_3.6.2          stringi_1.8.3      cachem_1.0.8       fs_1.6.3          \n[49] promises_1.2.1     remotes_2.4.2.1    ellipsis_0.3.2     generics_0.1.3    \n[53] vctrs_0.6.5        tools_4.2.1        glue_1.6.2         hms_1.1.3         \n[57] pkgload_1.3.4      fastmap_1.1.1      yaml_2.3.8         timechange_0.3.0  \n[61] colorspace_2.1-0   sessioninfo_1.2.2  memoise_2.0.1      knitr_1.45        \n[65] usethis_2.2.3      profvis_0.3.8     \n\n\n\n\n\nfffffffffff\n\n\nR\nPython\nsessionInfo\n\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\n# Beregn TF-IDF for hvert ord i hvert dokument\n# 1.: df består af entelte ord (tokens) med en TF værdi (udregnet ovenfor),\n#     hvor unikke_tokens repræsenterer alle unikke ord, som vi looper henover.\n# 2.: Hvert ord har en tilknyttet IDF-værdi, som er udregnet med \"bestem_idf\",\n#     og gemt i \"idf_scores\".\n# Det som dette loop gør er at multiplicere hver enkelt ord TF med IDF, og får\n# dermed TF-IDF for HVERT ORD i vores samlede dokumentdata.\nfor ord in unikke_tokens:\n    df[ord] = df[ord] * idf_scores[ord]\n\n# Print beregnede scores:\n# Hvad sker der her, hvor jeg indenfor [[...]] også anvender en vektor med alle unikke ord?\nprint(df[['dokument'] + unikke_tokens])\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidytext_0.4.2    segregation_1.1.0 lubridate_1.9.3   forcats_1.0.0    \n [5] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n [9] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11        here_1.0.1         lattice_0.22-5     png_0.1-8         \n [5] rprojroot_2.0.4    digest_0.6.33      utf8_1.2.4         mime_0.12         \n [9] R6_2.5.1           evaluate_1.0.1     pillar_1.9.0       rlang_1.1.2       \n[13] data.table_1.15.0  miniUI_0.1.1.1     urlchecker_1.0.1   Matrix_1.5-3      \n[17] reticulate_1.34.0  rmarkdown_2.28     devtools_2.4.5     RcppProgress_0.4.2\n[21] htmlwidgets_1.6.4  munsell_0.5.1      shiny_1.8.0        janeaustenr_1.0.0 \n[25] compiler_4.2.1     httpuv_1.6.14      xfun_0.41          pkgconfig_2.0.3   \n[29] pkgbuild_1.4.3     htmltools_0.5.7    tidyselect_1.2.0   fansi_1.0.6       \n[33] tzdb_0.4.0         withr_3.0.2        later_1.3.2        SnowballC_0.7.1   \n[37] grid_4.2.1         jsonlite_1.8.8     xtable_1.8-4       gtable_0.3.6      \n[41] lifecycle_1.0.4    magrittr_2.0.3     tokenizers_0.3.0   scales_1.3.0      \n[45] cli_3.6.2          stringi_1.8.3      cachem_1.0.8       fs_1.6.3          \n[49] promises_1.2.1     remotes_2.4.2.1    ellipsis_0.3.2     generics_0.1.3    \n[53] vctrs_0.6.5        tools_4.2.1        glue_1.6.2         hms_1.1.3         \n[57] pkgload_1.3.4      fastmap_1.1.1      yaml_2.3.8         timechange_0.3.0  \n[61] colorspace_2.1-0   sessioninfo_1.2.2  memoise_2.0.1      knitr_1.45        \n[65] usethis_2.2.3      profvis_0.3.8     \n\n\n\n\n\nTL;DR\nOpsummeret,\n\nKoden gennemgår hvert unikt ord i dokumenterne.\nVi tæller, hvor mange dokumenter (SMSer) der indeholder det specifikke ord.\nVi beregner IDF for hvert ord baseret på, hvor mange dokumenter det optræder i.\nIDF-værdierne gemmes i en dictionary (idf_scores), hvor hvert ord har en tilknyttet IDF-værdi.\nFor hvert ord multiplicerer vi den tilhørende TF og IDF værdi for at få TF-IDF\nTræning\nTest\nEvaluering"
  },
  {
    "objectID": "workshop.html#ml-exp",
    "href": "workshop.html#ml-exp",
    "title": "Workshops and teaching",
    "section": "Clustering techniques [en]",
    "text": "Clustering techniques [en]\nCase\nClustering\nThe aim of the analysis is to formulate a framework to meaningfully divide the school landscape into clusters based on grade-based scores and hold these grade-based clusters up against demographic characteristics of the schools. Thus, the aim of the analysis is to categorize schools based on performance in an exploratory framework, which later will be used in further descriptions of the school landscape.\nIn clustering analysis, the ‘distance’ between people is defined as the Euclidean distance. The euclidean distance is the shortest path between two point in space (i.e. a straight line). Most often, Euclidean^2 (L^2) is used.\n\n\\begin{aligned}\nd(\\mathbf{p}, \\mathbf{q}) = d(\\mathbf{q}, \\mathbf{p}) &= \\sqrt{ (q_{1}-p_{1})^2 + (q_{2}-p_{2})^2 + \\cdots +  (q_{n}-p_{n})^2 } \\\\\n&= \\sqrt{ \\sum_{i=1}^{n} (q_{i}-p_{i})^2}\n\\end{aligned}\n\nThere are many merging/linking rules in hierarchical clustering methods – from k-means to Ward’s. We’ll be using Ward’s method for this task for hierarchical clustering.\n\nIn Python, we use the de-facto standard; Pandas.\nIn R, we use the Rstudio standard rather than the classic R dataframe; tibbles.\n\n\n\n R\n Python\n sessionInfo()\n\n\n\n\ndf &lt;- vroom(\"wiz-schools_231121.tsv\")\n\n# Printing all columns and 10 rows\nhead(df) %&gt;% gt()\n\n\n\n\ndata = pd.read_csv(\"wiz-schools_231121.tsv\", sep='\\t')\n\n# Printing first 6 columns and first 10 rows of data\nprint(data.iloc[0:10, :])\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidytext_0.4.2    segregation_1.1.0 lubridate_1.9.3   forcats_1.0.0    \n [5] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n [9] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11        here_1.0.1         lattice_0.22-5     png_0.1-8         \n [5] rprojroot_2.0.4    digest_0.6.33      utf8_1.2.4         mime_0.12         \n [9] R6_2.5.1           evaluate_1.0.1     pillar_1.9.0       rlang_1.1.2       \n[13] data.table_1.15.0  miniUI_0.1.1.1     urlchecker_1.0.1   Matrix_1.5-3      \n[17] reticulate_1.34.0  rmarkdown_2.28     devtools_2.4.5     RcppProgress_0.4.2\n[21] htmlwidgets_1.6.4  munsell_0.5.1      shiny_1.8.0        janeaustenr_1.0.0 \n[25] compiler_4.2.1     httpuv_1.6.14      xfun_0.41          pkgconfig_2.0.3   \n[29] pkgbuild_1.4.3     htmltools_0.5.7    tidyselect_1.2.0   fansi_1.0.6       \n[33] tzdb_0.4.0         withr_3.0.2        later_1.3.2        SnowballC_0.7.1   \n[37] grid_4.2.1         jsonlite_1.8.8     xtable_1.8-4       gtable_0.3.6      \n[41] lifecycle_1.0.4    magrittr_2.0.3     tokenizers_0.3.0   scales_1.3.0      \n[45] cli_3.6.2          stringi_1.8.3      cachem_1.0.8       fs_1.6.3          \n[49] promises_1.2.1     remotes_2.4.2.1    ellipsis_0.3.2     generics_0.1.3    \n[53] vctrs_0.6.5        tools_4.2.1        glue_1.6.2         hms_1.1.3         \n[57] pkgload_1.3.4      fastmap_1.1.1      yaml_2.3.8         timechange_0.3.0  \n[61] colorspace_2.1-0   sessioninfo_1.2.2  memoise_2.0.1      knitr_1.45        \n[65] usethis_2.2.3      profvis_0.3.8     \n\n\n\n\n\nClean data"
  },
  {
    "objectID": "workshop.html#lda",
    "href": "workshop.html#lda",
    "title": "Workshops and teaching",
    "section": "LDA [da]",
    "text": "LDA [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\n\n\nHi! I’m a side note …………………………………. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, !\nXXX\n\n\nR\nPython\nsessionInfo\n\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\nimport matplotlib.pyplot as plt\n...\nplt.show()\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidytext_0.4.2    segregation_1.1.0 lubridate_1.9.3   forcats_1.0.0    \n [5] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n [9] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11        here_1.0.1         lattice_0.22-5     png_0.1-8         \n [5] rprojroot_2.0.4    digest_0.6.33      utf8_1.2.4         mime_0.12         \n [9] R6_2.5.1           evaluate_1.0.1     pillar_1.9.0       rlang_1.1.2       \n[13] data.table_1.15.0  miniUI_0.1.1.1     urlchecker_1.0.1   Matrix_1.5-3      \n[17] reticulate_1.34.0  rmarkdown_2.28     devtools_2.4.5     RcppProgress_0.4.2\n[21] htmlwidgets_1.6.4  munsell_0.5.1      shiny_1.8.0        janeaustenr_1.0.0 \n[25] compiler_4.2.1     httpuv_1.6.14      xfun_0.41          pkgconfig_2.0.3   \n[29] pkgbuild_1.4.3     htmltools_0.5.7    tidyselect_1.2.0   fansi_1.0.6       \n[33] tzdb_0.4.0         withr_3.0.2        later_1.3.2        SnowballC_0.7.1   \n[37] grid_4.2.1         jsonlite_1.8.8     xtable_1.8-4       gtable_0.3.6      \n[41] lifecycle_1.0.4    magrittr_2.0.3     tokenizers_0.3.0   scales_1.3.0      \n[45] cli_3.6.2          stringi_1.8.3      cachem_1.0.8       fs_1.6.3          \n[49] promises_1.2.1     remotes_2.4.2.1    ellipsis_0.3.2     generics_0.1.3    \n[53] vctrs_0.6.5        tools_4.2.1        glue_1.6.2         hms_1.1.3         \n[57] pkgload_1.3.4      fastmap_1.1.1      yaml_2.3.8         timechange_0.3.0  \n[61] colorspace_2.1-0   sessioninfo_1.2.2  memoise_2.0.1      knitr_1.45        \n[65] usethis_2.2.3      profvis_0.3.8"
  },
  {
    "objectID": "workshop.html#python",
    "href": "workshop.html#python",
    "title": "Workshops and teaching",
    "section": "Python [da]",
    "text": "Python [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem."
  },
  {
    "objectID": "workshop.html#r",
    "href": "workshop.html#r",
    "title": "Workshops and teaching",
    "section": "R [da]",
    "text": "R [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem."
  },
  {
    "objectID": "workshop.html#quarto",
    "href": "workshop.html#quarto",
    "title": "Workshops and teaching",
    "section": "Quarto [da]",
    "text": "Quarto [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem."
  },
  {
    "objectID": "workshop.html#cli",
    "href": "workshop.html#cli",
    "title": "Workshops and teaching",
    "section": "CommandLine and file organization [da]",
    "text": "CommandLine and file organization [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\nTerminalen: interaktion med computeren (og filsystemet)\n\nTerminalen er det, der giver os adgang til kommandolinjegrænsefladen (CLI). Selvom den har miste meget af sin position blandt den gennemsnitlige computer-bruger—grundet grafiske brugergrænseflader (GUI)—er den fortsat en meget effektiv måde at interagere med computeren. Særligt på Unix-systemer.\nShell\nNår vi anvender CLI, bruger vi en shell, der er et program til fortolkning af kommandoer. De to mest almindelige shell-programmer er:\n\n\nBash (Bourne Again Shell): Standard på mange Linux-distributioner og tidligere på macOS.\n\nZsh (Z Shell): Standard på macOS fra og med version 10.15 Catalina.\nFilorganisering\n\nReferer til hvordan vores filer (data) og mapper (directories) er struktureret og lagret på vores lagringsenhed (harddisk, SSD, ekstern enhed, …).\nDenne struktur bestemmer hvordan data hentes og gemmes, og gør det muligt for brugeren eller programmer at finde, tilgå og anvende filer.\nEn mappe (directory) er en container, som indeholder filer og andre mapper, og danner grundlaget for en hierakisk struktur (tree-/træstruktur). Opbygningen er med afsæt i en root-mappe (ikke den egentlige root-mappe, men brugerens hjemmemappe), som indeholder undermapper og filer. Herfra indeholder hver undermappe andre undermapper og filer, hvilket danner et træ af mapper og filer, hvis vi zoomer ud. Med andre ord, (træ-)hierakiet giver en logisk og navigérbar organisering på computeren.\n\nroot directory: I Unix-systemer (MacOS, Linux) betegnes den /. I Windows er der en root-mappe i hvert drev, betegnet med bogstavet for drevet, fx C:\\\nUndermapper: Mapper, der findes inde i andre mapper, fx /home/user/documents eller C:\\Users\\Username\\Documents.\nEt filsystem\n\n\n\nUNIX (MacOS, Linux)\n/\n├── bin                  # Vigtige eksekverbare systemfiler\n├── sbin                 # Systemadministrative eksekverbare filer\n├── etc                  # Systemkonfigurationsfiler\n├── home                 # Brugermapper (personlige filer)\n│   └── jeppe            # Brugeren \"jeppe\"'s hjemmemappe\n│       ├── Documents    # jeppes dokumenter\n│       ├── Downloads    # jeppes downloadede filer\n│       ├── Music        # jeppes musikfiler\n│       ├── Pictures     # jeppes billeder\n│       ├── Videos       # jeppes videofiler\n│       └── Projects     # Personlige kodeprojekter og scripts\n│           └── snake_game\n│               ├── main.py # Python-kode til et snake-spil\n│               └── assets  # Grafikfiler til spillet\n├── root                 # Superbrugerens hjemmemappe\n├── usr                  # Bruger- og systemprogrammer\n│   ├── bin              # Programmer installeret til brugere\n│   ├── lib              # Systemets biblioteker\n│   └── local            # Lokalt installerede programmer\n├── var                  # Variable data som logs og mails\n│   ├── log              # Systemets logfiler\n│   └── tmp              # Midlertidige filer\n├── tmp                  # Midlertidige filer (slettes ved genstart)\n├── dev                  # Systemets enheder som harddiske og terminaler\n├── mnt                  # Monteringspunkt for midlertidige enheder\n│   └── usb-drive        # En USB-nøgle monteret her\n└── media                # Monteringspunkt for eksterne enheder\n    └── jeppe-usb        # jeppes eksterne harddisk hvis monteret\n\n\n\nWindows\nC:\\\n├── Program Files            # Programmer installeret for alle brugere\n├── Program Files (x86)      # 32-bit versioner (på 64-bit systemer)\n├── Users                    # Brugermapper (til hver bruger på systemet)\n│   └── jeppe                # Brugeren \"jeppe\"'s hjemmemappe\n│       ├── Documents        # jeppes dokumenter\n│       ├── Downloads        # jeppes downloadede filer\n│       ├── Music            # jeppes musikfiler\n│       ├── Pictures         # jeppes billeder\n│       ├── Videos           # jeppes videofiler\n│       ├── Desktop          # Filer og genveje på jeppes skrivebord\n│       ├── AppData          # jeppes personlige app-data og indstillinger\n│       └── Projects         # Personlige kodeprojekter og scripts\n│           └── snake_game\n│               ├── main.py  # Python-kode til et snake-spil\n│               └── assets   # Grafikfiler til spillet\n├── Windows                  # Operativsystemets filer\n│   ├── System32             # Vigtige systemfiler \n│   └── Temp                 # Midlertidige filer, der bruges af systemet\n├── ProgramData              # Data, der deles af applikationer på systemet\n└── Temp                     # Midlertidige filer\n\n\n\n\nNavigation: Absolutte og relative stier\n\nAbsolut sti: En sti, der beskriver placeringen af en fil eller mappe i forhold til root-mappen. Fx /home/user/documents/projekt.docs eller C:\\Users\\Username\\Documents\\projekt.docx.\nRelativ sti: En sti, der beskriver placeringen af en fil eller mappe i forhold til den nuværende mappe. Hvis vi er i mappen /home/user, kan vi nøjes med den relative sti documents/projekt.docx for at henvise til filen.\n\n\n1ls\n     ls -l\n     ls -a\n\n2cd\n     cd ..\n     cd ~\n     cd -\n\n3touch filnavn.type\n\n4mkdir ny-mappe\n\n5rm filnavn.type\n\n6rm -r ny-mappe\n\n\n1\n\nLister filer og mapper i den aktuelle mappe. ls -l lister filer og mapper med detaljer (fx rettigheder, størrelse). ls -a viser alle filer, inklusiv skjulte filer.\n\n2\n\nSkifter til en anden mappe. cd .. går én mappe op/tilbage (til forældermappen). cd ~ går til brugerens hjemmemappe. cd - skifter tilbage til den seneste mappe, du var i.\n\n3\n\nOpretter en ny, tom fil med angivet navn og type.\n\n4\n\nOpretter en ny mappe med det angivne navn.\n\n5\n\nSletter en fil med det angivne navn.\n\n6\n\nSletter en mappe og alt indholdet i den rekursivt.\n\n\n\n\n\nEr navigation med CML nødvendigt? Nej. Men det kan give et flow, hvis vi primært laver kodearbejde da terminalen kan tilgås “indeni” programmer som Rstudio eller vscode. Men uanset om man bruger mus eller tastetur til at navigere på sin computer, er det vigtigt at vide, hvordan filer er organiseret, hvis man har en computer-baseret stilling."
  },
  {
    "objectID": "workshop.html#git",
    "href": "workshop.html#git",
    "title": "Workshops and teaching",
    "section": "Git [da]",
    "text": "Git [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\n\n.git and versioncontrol\nFor installation, se …\nVersionkontrol er et system (software), der holder styr på ændringer af filer over tid, der gør det muligt at genskabe vores tidligere arbejde. Virker for (stort set) alle filer.\nPå større projekter—hvor flere er involveret—er det vigtigt at have kontrol over, hvem der foretager ændringer, hvilke ændringer der er blevet foretaget, og hvordan man kan rulle tilbage til tidligere versioner, hvis noget går galt.\nI et langsigtet perspektiv vil Git hjælpe dig med at holde et projekt organiseret, muliggøre (mere) effektivt samarbejde og sikre, at vi altid har en backup af dine fremskridt.\n\n\nGør dette …\n/projektarbejde\n└──/backup\n    ├── projekt_281024.docx\n    ├── projekt_311024.docx\n    ├── projekt_041224.docx\n    ├── projekt_final.docx\n    ├── projekt_final2.docx\n    ├── projekt_final3.docx\n    ├── projekt_final_final.docx\n    └── projekt_FINAL.docx\n\n… til dette\n/projektarbejde\n├── .git\n└── projekt.docx\n\n\nGit i praksis\nVersionsstyringsprocessen med afsæt i .git skelletet består af 3 stadier:\n\nWorking Directory: den mappe, hvor vi kørte git init. Alt der ændres her spores af Git, men det gemmes (committes) ikke automatisk . Arbejdsområdet er der hvor .git er gemt og indeholder vores faktiske filer og mapper, som vi ser og redigerer på din computer. Når vi redigerer en fil i vores projekt, bliver ændringen først gjort i arbejdsområdet. Filer, der arbejdes på, får tagget M (modified), som betyder at Git har registeret en ændring, men den er ikke blevet gemt i versionshistorikken endnu.\nStaging Area: De ændringer, som du ønsker registreret i næste commit bliver flyttet til et staging area med git add . (se ④ nedenfor). Det er ikke som sådan et “sted”, men et snarer et “tag” til de filer, som Git skal gemme. Ingen ændringer er blevet gemt endnu. Det tekniske navn er index, og Stating Area er ikke et “sted” på computeren men en fil i .git mappen, der noterer hvad der skal sendes til versionshistorikken i næste git commit (se ⑥ nedenfor) og er et mellemstadie mellem Working Directory og Repository. Se det som et kladdeområde, hvor du forbereder de ændringer, der skal indgå i en commit. Vi sender filer til Staging Area med: git add. Den primære funktion er at holde vores versionshistorik ren og logisk opdelt. Hvilket gør det lettere at spore ændringer og identificere bugs senere. For at se hvad der er modificeret og/eller staged bruger vi: git status (se &#9314 nedenfor).\nRepository: Når vi bruger kommandoen git commit -m \"besked\" gemmes alt staged data i vores Git-repository og alle ændringer siden sidste commit bliver en permanent del af projektets versionshistorik. Vores repository er commit-historikken, hvor hver commit repræsenterer en version af projektet på et bestemt tidspunkt. Når filer er committed er det sikkert gemt i vores lokale database. Vi sender filer til versionshistorikken med: git commit &lt;fil&gt; (se ⑥ nedenfor). Vi tilgår historikken med: git log (se ⑦ nedenfor).\nBranching\nHver commit repræsenterer et punkt i projektets branch, og du kan navigere frem og tilbage i projektets historie efter behov.\nEn branch i Git repræsenterer en uafhængig udviklingslinje. Vi kan lave ændringer i denne branch uden at påvirke andre branches. Vi kan droppe en branch, hvis ideer var dårlig, eller merge den med vores primære branch, hvis det virkede. (Teknisk relaterer alt dette sig til HEAD-pointeren).\n“This makes using Git a joy because we know we can experiment without the danger of severely screwing things up.” (REF)\nEt sikkert workflow\n\n\nIsolering: Hver branch er isoleret fra andre branches, hvilket betyder, at ændringer i én branch ikke påvirker arbejdet i andre branches.\n\nSamarbejde: Udviklere kan arbejde på separate branches uden at forstyrre hinandens arbejde. Git gør det muligt at flette branches sammen, når arbejdet er færdigt.\n\nEksperimentering: Branches gør det nemt at eksperimentere med nye ideer uden risiko. Hvis noget går galt, kan du altid slette branch’en og vende tilbage til en stabil version.\nTilgå versionshistorikken og genskab tidligere stadie\ngit log\ngit checkout &lt;commit-id&gt;\nKommandoer\n\n1git config\n2git init\n3git status\n4git add\n5git diff\n6git commit\n7git log\n8git clone\n9git push\n10git pull\n11git remote\n\n\n1\n\nIndstilling af konfigurationsindstillinger (fx brugernavn og e-mail).\n\n2\n\nInitialiserer et nyt Git-repository i den aktuelle mappe. I skal være opmærksom på hvilken mappe I befinder jer i, når i kører git init.\n\n3\n\nViser status for ændringer i arbejdsområdet (fx hvilke filer der er ændret og klar til staging).\n\n4\n\nTilføjer filer til staging-området, så de er klar til næste commit.\n\n5\n\nViser forskelle mellem ændringer i filer, enten fra arbejdsområdet eller staging-området.\n\n6\n\nGemmer de ændringer, der er i staging-området, som en ny version i repository.\n\n7\n\nViser en log over commits i repository, ofte med detaljer som forfatter, dato og commit-besked.\n\n8\n\nHenter et eksisterende repository fra en ekstern kilde (fx GitHub) og opretter en lokal kopi.\n\n9\n\nSender lokale commits til et eksternt repository.\n\n10\n\nHenter og integrerer ændringer fra et eksternt repository til den lokale kopi.\n\n11\n\nAdministrerer forbindelser til eksterne repositories.\n\n\n\n\nI ① … ② Kommandoen skaber en ny undermappe (.git) og er “skelettet” for vores repository. Denne mappe indeholder alle Git’s interne data, der bruges til at spore og administrere versionshistorikken for dit projekt. ③ … ④ … ⑤ … ⑥ … ⑦ … ⑧ … ⑨ … ⑩ … ⑪ …\nLokalt repository\nDet lokale repository, er det ligger på vores lokalecomputer (.git mappen).\nFjern repository\nGrundlæggende fungerer et fjernrepositoryet som et centralt lager på en server, som flere udviklere kan samarbejde om. Disser servere er typisk hostet på platforme som GitHub eller GitLab.\nEt fjernrepositoty kan klones (se ⑧ ovenfor) til vores lokale computer, således vi har en lokal kopi af projektet. Herefter kan vi pull’e og push’e ændringer:\n\n\nPull: Henter ændringer fra fjernrepository’et til dit lokale repository.\n\nPush: Skubber ændringer fra dit lokale repository til fjernrepository’et.\nDistribueret versionskontrol\nGit er et distribueret versionskontrolsystem, hvilket betyder, at hver udvikler har en fuld kopi af hele repositoryet (inklusive historik og branches) på deres egen computer.\nØvelse"
  },
  {
    "objectID": "workshop.html#plaintext",
    "href": "workshop.html#plaintext",
    "title": "Workshops and teaching",
    "section": "Plain text [da]",
    "text": "Plain text [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\nPlain text"
  },
  {
    "objectID": "workshop.html#api",
    "href": "workshop.html#api",
    "title": "Workshops and teaching",
    "section": "API’s [da]",
    "text": "API’s [da]\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem.\nAPI’s"
  },
  {
    "objectID": "workshop/lda.html",
    "href": "workshop/lda.html",
    "title": "",
    "section": "",
    "text": "XXX\n\nRPythonsessionInfo\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\nimport matplotlib.pyplot as plt\n...\nplt.show()\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11       lattice_0.22-5    png_0.1-8         digest_0.6.33    \n [5] grid_4.2.1        jsonlite_1.8.8    evaluate_0.23     rlang_1.1.2      \n [9] cli_3.6.2         rstudioapi_0.15.0 Matrix_1.5-3      reticulate_1.34.0\n[13] rmarkdown_2.28    tools_4.2.1       htmlwidgets_1.6.4 xfun_0.42        \n[17] yaml_2.3.8        fastmap_1.1.1     compiler_4.2.1    htmltools_0.5.7  \n[21] knitr_1.45"
  },
  {
    "objectID": "workshop/api.html",
    "href": "workshop/api.html",
    "title": "",
    "section": "",
    "text": "API’s"
  },
  {
    "objectID": "workshop/nb.html",
    "href": "workshop/nb.html",
    "title": "",
    "section": "",
    "text": "Case …\n\n\nSuperviseret Machine Learning (SML)\nI dag er fokus kun på superviseret ML, da vi kun har en enkelt workshop i dag og der vil være for mange statistiske forudsætninger til de to andre hovedtyper.\nSML fungerer ved, at vi giver modellen data, hvor vi kender det rigtige svar. Det kunne være, om en besked er spam eller ej, om et produkt er populær baseret på salgsdata, eller hvilken temperatur der vil være i morgen baseret på historiske målinger.\n\nI besked-eksemplet vil det altså sige at vi har et datasæt bestående af SMSer, hvor hver SMS i den data vi træner vores model på er kodet, dvs. tilskrevet et label, der indikerer om SMSen er spam (label=1) eller ikke-spam – “ham” – (label=0).\n\nModellen lærer sammenhænge mellem de inputdata (features, ord), som vi fodrer den med, og de kendte svar (labels, spam/ham). Når modellen er trænet, og den er vurderet til at være god nok, kan vi bruge den til at forudsige labels for nye data, hvor vi ikke kender svaret på forhånd.\nDet største problem i at arbejde med tekst i ML er at ML-algoritme ikke kan arbejde direkte med tekst. De kræver numeriske inputs for at kunne udføre matematiske operationer (se grundbog).\nVi er altså nødt til at konvertere tekst til en numerisk repræsentation. I denne kontekst kaldes denne proces for vectorisering.\nI denne proces transformerer og repræsenterer vi hvert tekstdokument (fx en SMS) som en række tal eller en vektor.\n\n\nKlassifikationsalgoritme\nNaive Bayes er en algoritme til at løse et konkret klassifikationsproblem relateret til naturligt sprog\nNaive Bayes er en probabilistisk klassifikationsmodel, baseret på Bayes’ teorem. Algoritmen fungerer ved at beregne sandsynligheden for, at en besked tilhører en bestemt klasse, givet dens indhold (dvs. de ord, der optræder i beskeden).\nModellen kaldes for “Naiv” grundet en central antagelse om at alle features (i vores tilfælde ord) er uafhængige af hinanden. Denne antagelse er ikke realistisk, da ord normalt ikke optræder helt uafhængigt af hinanden (ord i sætninger er ofte afhængige af hinanden). Det gør algoritmen enkel og hurtig, og den fungerer alligevel godt i praksis, som er blevet illustreret i tekniske detaljer mange steder.\nModellens formål er at lære forholdet mellem de inputdata, vi giver den (features), og de kendte labels, så den kan forudsige labels for nye, ukendte data.\nDet vil altså sige at vi har med et klassifikationsproblem at gøre. Modellen skal forudsige, hvilken kategori noget tilhører, og virke som et spam-filter, hvor vi klassificerer beskeder som enten “spam” eller “ikke-spam”, og i en praktisk applikation kan sende indkomne beskeder ind i forskellige mapper, som I kender fra jeres e-mail.\n\nBayes’ Teorem\nBayes’ Theorem handler om at beregne betingede sandsynligheder, der giver os en måde at opdatere vores viden baseret på nye data. Det har givet navn til en hel gren i statistikke, bayesisk statistik, som står i kontrast til frekvensstatistik (som er det i med al sandsynlighed kender fra gymnasiet og det i skal lære på 4. semester).\nBayes’ teorem er givet ved:\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\nHvor,\n\nP(A∣B): Sandsynligheden for A, givet B. Dette kalder vi den posterior sandsynligheden.\nP(B∣A): Sandsynligheden for B, givet A. Dette kalder vi likelihood (betinget sandsynlighed).\nP(A): Sandsynligheden for A uden at tage hensyn til B. Dette kalder vi prior sandsynligheden.\nP(B): Sandsynligheden for B, uanset hvad A er.\n\nI kontekst og i en klassifikationssammenhæng er:\n\nA klassen (spam eller ham), og\nB er de observerede data (de ord, der optræder i beskeden).\n\nog det vi er interesserde i er at bestemme P(spam∣ord): sandsynligheden for, at en besked er spam, givet at visse ord optræder.\nRepitation af formål og hvad vi vil implementere i Python er:\n\nSandsynligheden for at en SMS er spam, baseret på fremkomsten/tilstedeværelsen af et givent ord, er proportionelt til sandsynligheden for at ordet fremkommer i spam-SMSer og den a priori sandsynlighed for at en tilfældig SMS er spam.\n\n\nP(\\text{spam}|ord)\\propto P(ord|\\text{spam}) P(\\text{spam})\n\n\nSpg.: Hvordan implimenterer vi denne model i Python på en måde, der kan “lære” maskinen at genkende spam-SMSer?\n\n\n\nAnvendelse af algoritmen til tekstklassificering\nVi bruger Naive Bayes til tekstklassifikation for at forudsige om en besked er spam eller ham baseret på sandsynligheden for de enkelte ord, der optræder i beskeden, tilhører en given klasse.\nDen generelle Naive Bayes-klassifikator for to klasser (spam eller ikke-spam) er formuleret som:\n \\hat{y} = \\underset{c}{\\operatorname{argmax}} \\ P(c) \\prod_{i=1}^{n} P(x_i | c) \nHvor,\n\n\\hat{y} er den forudsagte klasse.\nc er en af klasserne (spam eller ikke-spam).\nP(c) er prior sandsynligheden for klassen c (sandsynligheden for, at en tilfældig besked er spam).\nP(x_{i}∣c) er sandsynligheden for ordet x_{i}, givet klassen c.\nn er antallet af ord i beskeden.\n\nMed formlen beregner vi sandsynligheden for, at en besked tilhører hver klasse (spam eller ikke-spam), og vælger den klasse, der har den højeste sandsynlighed: Vi vælger den klasse (c), hvor P(c|x) er størst, indikeret i formlen med \\underset{c}{\\operatorname{argmax}}\nFremgangsmåde:\n\nPrior sandsynlighed, P(c), beregnes ved at tælle, hvor mange af vores træningsbeskeder, der er spam i forhold til det samlede antal beskeder: P(spam)= \\frac{\\text{Antal spam-beskeder}}{\\text{Totalt antal beskeder}}\nLikelihood (betinget sandsynlighed), P(x_{i}∣c) beregnes som: P(x_{i}∣spam)= \\frac{\\text{Antal spam-beskeder, der indeholder } x_{i}}{\\text{Antal spam-beskeder totalt}}\n\nHvad vi er udregner, er hvor ofte hvert unikke ord i vores SAMLEDE TEKSTMATERIALE optræder i spam-beskeder (eller ikke-spam-beskeder), og produktet af sandsynlighederne for hvert enkelt ord i en given tekst, definere om teksten sandsynligvis er spam (eller ikke-spam)\nSelvom algoritmen er “naiv” og antagelsen om at alle ord er uafhængige, i praksis som udgangspunkt ikke holder, bestemmer vi stadig sandsynligheden for om en besked er spam eller ham som produktet af sandsynlighederne for de enkelte ord. Det er mange gange vist at denne “fejlantagelse” ikke er et problem i større mængder tekstdata.\n\nVi bruger træningsdata til at beregne P(spam) og P(ham)\nVi beregner sandsynlighederne for ordene “Congratulations”, “won”, “free”, osv. under begge klasser (spam og ham). Altså, hvad er sandsynligheden for at “free” (x_{free}) tilhører hhv. spam og ham klassen, givet fremkomsten af x_{free} i SMSer klassificeret som spam eller ham.\nVi multiplicerer sandsynlighederne for de enkelte ord – $x_{Congratulation} + x_{won} + x_{free} + $ – og vælger den klasse med den højeste sandsynlighed. Altså, hvert ord i en SMS har en sandsynlighed for at tilhører spam eller ham, og givet disse enkelte ord, hvor sandsynligt er det så for at SMS i sin helhed er spam eller ham.\n\nAltså, hvis ord som “won” og “free” ofte forekommer i spam-beskeder, vil Naive Bayes tildele beskeder med (store) fremkomster af disse ord en høj sandsynlighed for at være spam, og med denne sandsynlighedsargumentation klassificere SMSen som spam.\n\n\nEn lille, men central, sidebemærkning…\nDer kan opstå en problematisk udfordring, hvis et ord i udenfor vores træningsdata ikke fremgår i træningsdataen, da det vil “nulstille” den samlede sandsynlighed når vi multiplicerer.\nDette overkommes ved at inkludere en metode, der kaldes Laplace-smoothing, hvor alle betingede sandsynligheder tilføjes en lille konstant (værdi), således at ingen sandsynligheder er 0:\nP(x_{i}∣c)= \\frac{\\text{Totalt antal ord i klassen }+V}{\\text{Antal gange ordet optræder i klassen} +1}\nHvor, V er størrelsen af ordforrådet i vores corpus (antallet af unikke ord i træningsdataene). Med dette undgår vi nul-sandsynligheder.\n\n\nModel-træning\nI arbejdet med superviseret Machine Learning arbejder vi med vores data som opdelt i hhv. trænings- og testdata. Den data vi arbejder med, er et datasæt som vi har kvalitativt kodet med de korrekte labels ud fra vores forhåndsviden. Med denne opdeling er det muligt både at træne vores model og evaluere vores model, for at kunne vurdere hvordan modellen performer på nye, usete data.\n\n\nTræningsdata\nTræningsdataen er det datasæt, som vi træner vores model på. Datasættet indeholder både features (ord) og labels (korrekte kategorier). Det vil sige, vi ved altså hvad den rigtige kategori til vores tekster er, for at vores model at udregne det mønster, der kendetegner hver kategori.\nMed andre ord, når vi træner en Naive Bayes-model, “lærer” den at forstå sammenhængen mellem de input og de tilknyttede labels.\nEn klassisk opdeling er, at træningsdataen udgør 80% af den kvalitativt kodet data.\n\n\nTestdata\nTestdata udgør den anden del af den kvalitativt kodede data (her 20%). Testdataene bruges til at evaluere modelens præstation og generaliseringsevne og formålet med testdata er at give et mål for, hvordan modellen vil præstere på nye, usete data. Det vil altså sige at modellen ikke har “set” denne data (og er grunden til at vi skal have Laplace Smoothing…)\n\n\n\nEksempel …\n\nKlargøring af tekstdata\nDer er flere måde, hvorpå vi kan vektoriserer tekster, men centrale of typiske i denne form for analyse er:\n\nBag of Words (BoW)\nTF-IDF (Term Frequency-Inverse Document Frequency)\n\n\nBoW\nBag of Words er den mest simpel metode til at transformere tekst til numerisk form. Det fungerer ved at tælle, hvor mange gange hvert ord forekommer i et dokument, uden at tage højde for ordets rækkefølge eller kontekst. Resultatet er en vektor, der repræsenterer frekvensen af hvert ord i dokumentet. Eksempel på BoW:\nTekst 1: Jeg elsker spam\nTekst 2: Jeg kan ikke fordrage spam\nFørst opretter vi et ordforråd (vocabulary) baseret på alle de unikke ord i vores dokumenter:\n\nRPythonsessionInfo\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\nvocab = ['Jeg', 'elsker', 'spam', 'kan', 'ikke', 'fordrage']\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11       lattice_0.22-5    png_0.1-8         digest_0.6.33    \n [5] grid_4.2.1        jsonlite_1.8.8    evaluate_0.23     rlang_1.1.2      \n [9] cli_3.6.2         rstudioapi_0.15.0 Matrix_1.5-3      reticulate_1.34.0\n[13] rmarkdown_2.28    tools_4.2.1       htmlwidgets_1.6.4 xfun_0.42        \n[17] yaml_2.3.8        fastmap_1.1.1     compiler_4.2.1    htmltools_0.5.7  \n[21] knitr_1.45       \n\n\n\n\n\nffffffffffff\n\nRPythonsessionInfo\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\ntekst1 = [1, 1, 1, 0, 0, 0]\ntekst2 = [1, 0, 1, 1, 1, 1]\ndf = pd.DataFrame([tekst1, tekst2], columns=vocab, index=['tekst1', 'tekst2'])\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11       lattice_0.22-5    png_0.1-8         digest_0.6.33    \n [5] grid_4.2.1        jsonlite_1.8.8    evaluate_0.23     rlang_1.1.2      \n [9] cli_3.6.2         rstudioapi_0.15.0 Matrix_1.5-3      reticulate_1.34.0\n[13] rmarkdown_2.28    tools_4.2.1       htmlwidgets_1.6.4 xfun_0.42        \n[17] yaml_2.3.8        fastmap_1.1.1     compiler_4.2.1    htmltools_0.5.7  \n[21] knitr_1.45       \n\n\n\n\n\nffffffffffff\n\n\nTF-IDF\nTF-IDF tager, i modsætning til BoW, højde for, hvor ofte et ord forekommer i en tekst, i forhold til hvor ofte det forekommer i hele datasættet. Dette hjælper med at nedvægte meget almindelige ord (såsom “is”, “am,”the”, osv.), som sandsynligvis ikke bidrager meget til meningen af dokumentet, og fremhæve ord, der er særligt vigtige for den specifikke besked (såsom “free”, “won”).\nTF-IDF for et ord x i et dokument d er givet ved:\n\\text{TF-IDF}(x,d)=\\text{TF}(x,d) \\times \\text{IDF}(x)\nHvor:\n\nTF (Term Frequency): Måler hvor ofte ordet x forekommer i dokumentet d.\nIDF (Inverse Document Frequency): log ⁡\\left( \\frac{N}{df(x)} \\right ), hvor N er det totale antal dokumenter, og df(x) er antallet af dokumenter, som indeholder x.\n\nHermed sikrer vi at vi ikke vægter almindelige ord for højt, men i stedet fokuserer på de vigtigere ord.\n\nRPythonsessionInfo\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\ncorpus = [\"Jeg elsker spam\",\"Jeg kan ikke fordrage spam\"]\n\ndf = pd.DataFrame({'dokument': corpus})\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11       lattice_0.22-5    png_0.1-8         digest_0.6.33    \n [5] grid_4.2.1        jsonlite_1.8.8    evaluate_0.23     rlang_1.1.2      \n [9] cli_3.6.2         rstudioapi_0.15.0 Matrix_1.5-3      reticulate_1.34.0\n[13] rmarkdown_2.28    tools_4.2.1       htmlwidgets_1.6.4 xfun_0.42        \n[17] yaml_2.3.8        fastmap_1.1.1     compiler_4.2.1    htmltools_0.5.7  \n[21] knitr_1.45       \n\n\n\n\n\nffffffffffff\n\nRPythonsessionInfo\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\n# Beregn TF for hvert ord i dokumentet:\n\n# Tokenisere dokumenter:\n# hvad kalder vi det når vi skriver .apply(lambda x: ...)?\n# og hvad sker der?\ndf['tokens'] = df['dokument'].apply(lambda x: x.split())\n\n# Beregn antallet af ord i hvert dokument\n# Hvad sker der her?\ndf['total_ord'] = df['tokens'].apply(len)\n\n# En liste af alle tokens:\n# 1. Vi looper først over hver sublist i df['tokens'], der er alle ord i en tekst. Dvs. vi looper over hver række i kolonnen 'tokens'.\n# 2. Når vi har en specifik sublist, \"liste_med_ord\", looper vi nu over hvert enkelt token (ord, x) i denne subliste.\n# 3. For hvert token i hver sublist, føjes dette token til den nye liste alle_tokens med .append().\nalle_tokens = []\nfor liste_med_ord in df['tokens']:\n    for x in liste_med_ord:\n        alle_tokens.append(x)\n\n# Find de unikke tokens:\n# \"set()\" funktion er kun at gemme unikke elementer/værdier\n# \"sorted()\" er med for at organisere vores tokens alfabetisk, men er som sådan ikke nødvendig. Prøv evt. uden.\nunikke_tokens = sorted(set(alle_tokens))\n\n# Udregn TF for hvert dokument for hvert ord\nfor ord in unikke_tokens:\n    df[ord] = df['tokens'].apply(lambda x: x.count(ord) / len(x))\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11       lattice_0.22-5    png_0.1-8         digest_0.6.33    \n [5] grid_4.2.1        jsonlite_1.8.8    evaluate_0.23     rlang_1.1.2      \n [9] cli_3.6.2         rstudioapi_0.15.0 Matrix_1.5-3      reticulate_1.34.0\n[13] rmarkdown_2.28    tools_4.2.1       htmlwidgets_1.6.4 xfun_0.42        \n[17] yaml_2.3.8        fastmap_1.1.1     compiler_4.2.1    htmltools_0.5.7  \n[21] knitr_1.45       \n\n\n\n\n\nfffffffffff\n\nRPythonsessionInfo\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\n# Beregn IDF for hvert ord i dokumentet:\n\nimport math # For at få log()-funktionen\n\n# Beregne IDF for hvert ord\n# 1. Definer funktion\ndef bestem_idf(ord, df):\n    # Antal dokumenter der indeholder ordet\n    # 2.: df['tokens'] er en kollonne i vores DataFrame (df)\n    # 3.: .apply(lambda x: ord in x) for hvert dokument (SMS),\n    #     repræsenteret som en liste af ord, tjekker vi om ordet er til stede\n    #     i dokumentet. Funktionen returnerer TRUE eller FALSE (ord in x: True or False?)\n    # 4.: TRUE og FALSE repræsenteres nummerisk som 1 og 0. Ved at summere alle 1ere og 0ere,\n    #     får vi antallet af dokumenter, der indeholder ord x.\n    doks_med_ord = df['tokens'].apply(lambda x: ord in x).sum()\n    # Beregn IDF\n    # 5.: len() giver en værdi for antallet af dokumenter (SMSer). Tælleren i formlen.\n    #     (1 + doks_med_ord) er nævneren i formlen\n    #     .log(...) tager logaritmen.\n    return math.log(len(df) / (1 + doks_med_ord))\n\n# Beregn IDF for hvert unikke ord\n    # 6. Dette kalder vi en \"dictionary comprehension\", fordi koden her går\n    #    gennem alle ord i unikke_tokens og for HVERT ORD i unikke_tokens\n    #    kaldes vores definerede funktion \"bestem_idf\" og tilknytter en IDF-score\n    #    til dette ord.\nidf_scores = {ord: bestem_idf(ord, df) for ord in unikke_tokens}\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11       lattice_0.22-5    png_0.1-8         digest_0.6.33    \n [5] grid_4.2.1        jsonlite_1.8.8    evaluate_0.23     rlang_1.1.2      \n [9] cli_3.6.2         rstudioapi_0.15.0 Matrix_1.5-3      reticulate_1.34.0\n[13] rmarkdown_2.28    tools_4.2.1       htmlwidgets_1.6.4 xfun_0.42        \n[17] yaml_2.3.8        fastmap_1.1.1     compiler_4.2.1    htmltools_0.5.7  \n[21] knitr_1.45       \n\n\n\n\n\nfffffffffff\n\nRPythonsessionInfo\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\n# Beregn TF-IDF for hvert ord i hvert dokument\n# 1.: df består af entelte ord (tokens) med en TF værdi (udregnet ovenfor),\n#     hvor unikke_tokens repræsenterer alle unikke ord, som vi looper henover.\n# 2.: Hvert ord har en tilknyttet IDF-værdi, som er udregnet med \"bestem_idf\",\n#     og gemt i \"idf_scores\".\n# Det som dette loop gør er at multiplicere hver enkelt ord TF med IDF, og får\n# dermed TF-IDF for HVERT ORD i vores samlede dokumentdata.\nfor ord in unikke_tokens:\n    df[ord] = df[ord] * idf_scores[ord]\n\n# Print beregnede scores:\n# Hvad sker der her, hvor jeg indenfor [[...]] også anvender en vektor med alle unikke ord?\nprint(df[['dokument'] + unikke_tokens])\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11       lattice_0.22-5    png_0.1-8         digest_0.6.33    \n [5] grid_4.2.1        jsonlite_1.8.8    evaluate_0.23     rlang_1.1.2      \n [9] cli_3.6.2         rstudioapi_0.15.0 Matrix_1.5-3      reticulate_1.34.0\n[13] rmarkdown_2.28    tools_4.2.1       htmlwidgets_1.6.4 xfun_0.42        \n[17] yaml_2.3.8        fastmap_1.1.1     compiler_4.2.1    htmltools_0.5.7  \n[21] knitr_1.45       \n\n\n\n\n\n\n\nTL;DR\nOpsummeret,\n\nKoden gennemgår hvert unikt ord i dokumenterne.\nVi tæller, hvor mange dokumenter (SMSer) der indeholder det specifikke ord.\nVi beregner IDF for hvert ord baseret på, hvor mange dokumenter det optræder i.\nIDF-værdierne gemmes i en dictionary (idf_scores), hvor hvert ord har en tilknyttet IDF-værdi.\nFor hvert ord multiplicerer vi den tilhørende TF og IDF værdi for at få TF-IDF\n\n\n\n\nTræning\n\n\nTest\n\n\nEvaluering"
  },
  {
    "objectID": "workshop/git.html",
    "href": "workshop/git.html",
    "title": "",
    "section": "",
    "text": ".git and versioncontrol\nFor installation, se …\nVersionkontrol er et system (software), der holder styr på ændringer af filer over tid, der gør det muligt at genskabe vores tidligere arbejde. Virker for (stort set) alle filer.\nPå større projekter—hvor flere er involveret—er det vigtigt at have kontrol over, hvem der foretager ændringer, hvilke ændringer der er blevet foretaget, og hvordan man kan rulle tilbage til tidligere versioner, hvis noget går galt.\nI et langsigtet perspektiv vil Git hjælpe dig med at holde et projekt organiseret, muliggøre (mere) effektivt samarbejde og sikre, at vi altid har en backup af dine fremskridt.\n\n\nGør dette …\n/projektarbejde\n└──/backup\n    ├── projekt_281024.docx\n    ├── projekt_311024.docx\n    ├── projekt_041224.docx\n    ├── projekt_final.docx\n    ├── projekt_final2.docx\n    ├── projekt_final3.docx\n    ├── projekt_final_final.docx\n    └── projekt_FINAL.docx\n\n… til dette\n/projektarbejde\n├── .git\n└── projekt.docx\n\n\n\nGit i praksis\nVersionsstyringsprocessen med afsæt i .git skelletet består af 3 stadier:\n\nWorking Directory: den mappe, hvor vi kørte git init. Alt der ændres her spores af Git, men det gemmes (committes) ikke automatisk . Arbejdsområdet er der hvor .git er gemt og indeholder vores faktiske filer og mapper, som vi ser og redigerer på din computer. Når vi redigerer en fil i vores projekt, bliver ændringen først gjort i arbejdsområdet. Filer, der arbejdes på, får tagget M (modified), som betyder at Git har registeret en ændring, men den er ikke blevet gemt i versionshistorikken endnu.\nStaging Area: De ændringer, som du ønsker registreret i næste commit bliver flyttet til et staging area med git add . (se ④ nedenfor). Det er ikke som sådan et “sted”, men et snarer et “tag” til de filer, som Git skal gemme. Ingen ændringer er blevet gemt endnu. Det tekniske navn er index, og Stating Area er ikke et “sted” på computeren men en fil i .git mappen, der noterer hvad der skal sendes til versionshistorikken i næste git commit (se ⑥ nedenfor) og er et mellemstadie mellem Working Directory og Repository. Se det som et kladdeområde, hvor du forbereder de ændringer, der skal indgå i en commit. Vi sender filer til Staging Area med: git add. Den primære funktion er at holde vores versionshistorik ren og logisk opdelt. Hvilket gør det lettere at spore ændringer og identificere bugs senere. For at se hvad der er modificeret og/eller staged bruger vi: git status (se &#9314 nedenfor).\nRepository: Når vi bruger kommandoen git commit -m \"besked\" gemmes alt staged data i vores Git-repository og alle ændringer siden sidste commit bliver en permanent del af projektets versionshistorik. Vores repository er commit-historikken, hvor hver commit repræsenterer en version af projektet på et bestemt tidspunkt. Når filer er committed er det sikkert gemt i vores lokale database. Vi sender filer til versionshistorikken med: git commit &lt;fil&gt; (se ⑥ nedenfor). Vi tilgår historikken med: git log (se ⑦ nedenfor).\n\n\n\nBranching\nHver commit repræsenterer et punkt i projektets branch, og du kan navigere frem og tilbage i projektets historie efter behov.\nEn branch i Git repræsenterer en uafhængig udviklingslinje. Vi kan lave ændringer i denne branch uden at påvirke andre branches. Vi kan droppe en branch, hvis ideer var dårlig, eller merge den med vores primære branch, hvis det virkede. (Teknisk relaterer alt dette sig til HEAD-pointeren).\n“This makes using Git a joy because we know we can experiment without the danger of severely screwing things up.” (REF)\n\nEt sikkert workflow\n\nIsolering: Hver branch er isoleret fra andre branches, hvilket betyder, at ændringer i én branch ikke påvirker arbejdet i andre branches.\nSamarbejde: Udviklere kan arbejde på separate branches uden at forstyrre hinandens arbejde. Git gør det muligt at flette branches sammen, når arbejdet er færdigt.\nEksperimentering: Branches gør det nemt at eksperimentere med nye ideer uden risiko. Hvis noget går galt, kan du altid slette branch’en og vende tilbage til en stabil version.\n\n\n\nTilgå versionshistorikken og genskab tidligere stadie\ngit log\ngit checkout &lt;commit-id&gt;\n\n\n\n\nKommandoer\n\n1git config\n2git init\n3git status\n4git add\n5git diff\n6git commit\n7git log\n8git clone\n9git push\n10git pull\n11git remote\n\n\n1\n\nIndstilling af konfigurationsindstillinger (fx brugernavn og e-mail).\n\n2\n\nInitialiserer et nyt Git-repository i den aktuelle mappe. I skal være opmærksom på hvilken mappe I befinder jer i, når i kører git init.\n\n3\n\nViser status for ændringer i arbejdsområdet (fx hvilke filer der er ændret og klar til staging).\n\n4\n\nTilføjer filer til staging-området, så de er klar til næste commit.\n\n5\n\nViser forskelle mellem ændringer i filer, enten fra arbejdsområdet eller staging-området.\n\n6\n\nGemmer de ændringer, der er i staging-området, som en ny version i repository.\n\n7\n\nViser en log over commits i repository, ofte med detaljer som forfatter, dato og commit-besked.\n\n8\n\nHenter et eksisterende repository fra en ekstern kilde (fx GitHub) og opretter en lokal kopi.\n\n9\n\nSender lokale commits til et eksternt repository.\n\n10\n\nHenter og integrerer ændringer fra et eksternt repository til den lokale kopi.\n\n11\n\nAdministrerer forbindelser til eksterne repositories.\n\n\n\n\nI ① … ② Kommandoen skaber en ny undermappe (.git) og er “skelettet” for vores repository. Denne mappe indeholder alle Git’s interne data, der bruges til at spore og administrere versionshistorikken for dit projekt. ③ … ④ … ⑤ … ⑥ … ⑦ … ⑧ … ⑨ … ⑩ … ⑪ …\n\nLokalt repository\nDet lokale repository, er det ligger på vores lokalecomputer (.git mappen).\n\n\nFjern repository\nGrundlæggende fungerer et fjernrepositoryet som et centralt lager på en server, som flere udviklere kan samarbejde om. Disser servere er typisk hostet på platforme som GitHub eller GitLab.\nEt fjernrepositoty kan klones (se ⑧ ovenfor) til vores lokale computer, således vi har en lokal kopi af projektet. Herefter kan vi pull’e og push’e ændringer:\n\nPull: Henter ændringer fra fjernrepository’et til dit lokale repository.\nPush: Skubber ændringer fra dit lokale repository til fjernrepository’et.\n\n\n\nDistribueret versionskontrol\nGit er et distribueret versionskontrolsystem, hvilket betyder, at hver udvikler har en fuld kopi af hele repositoryet (inklusive historik og branches) på deres egen computer.\n\n\n\nØvelse"
  },
  {
    "objectID": "workshop/cli-file.html",
    "href": "workshop/cli-file.html",
    "title": "",
    "section": "",
    "text": "Terminalen: interaktion med computeren (og filsystemet)\nTerminalen er det, der giver os adgang til kommandolinjegrænsefladen (CLI). Selvom den har miste meget af sin position blandt den gennemsnitlige computer-bruger—grundet grafiske brugergrænseflader (GUI)—er den fortsat en meget effektiv måde at interagere med computeren. Særligt på Unix-systemer.\n\nShell\nNår vi anvender CLI, bruger vi en shell, der er et program til fortolkning af kommandoer. De to mest almindelige shell-programmer er:\n\nBash (Bourne Again Shell): Standard på mange Linux-distributioner og tidligere på macOS.\nZsh (Z Shell): Standard på macOS fra og med version 10.15 Catalina.\n\n\n\n\nFilorganisering\nReferer til hvordan vores filer (data) og mapper (directories) er struktureret og lagret på vores lagringsenhed (harddisk, SSD, ekstern enhed, …).\nDenne struktur bestemmer hvordan data hentes og gemmes, og gør det muligt for brugeren eller programmer at finde, tilgå og anvende filer.\nEn mappe (directory) er en container, som indeholder filer og andre mapper, og danner grundlaget for en hierakisk struktur (tree-/træstruktur). Opbygningen er med afsæt i en root-mappe (ikke den egentlige root-mappe, men brugerens hjemmemappe), som indeholder undermapper og filer. Herfra indeholder hver undermappe andre undermapper og filer, hvilket danner et træ af mapper og filer, hvis vi zoomer ud. Med andre ord, (træ-)hierakiet giver en logisk og navigérbar organisering på computeren.\n\nroot directory: I Unix-systemer (MacOS, Linux) betegnes den /. I Windows er der en root-mappe i hvert drev, betegnet med bogstavet for drevet, fx C:\\\nUndermapper: Mapper, der findes inde i andre mapper, fx /home/user/documents eller C:\\Users\\Username\\Documents.\n\n\n\nEt filsystem\n\n\n\nUNIX (MacOS, Linux)\n/\n├── bin                  # Vigtige eksekverbare systemfiler\n├── sbin                 # Systemadministrative eksekverbare filer\n├── etc                  # Systemkonfigurationsfiler\n├── home                 # Brugermapper (personlige filer)\n│   └── jeppe            # Brugeren \"jeppe\"'s hjemmemappe\n│       ├── Documents    # jeppes dokumenter\n│       ├── Downloads    # jeppes downloadede filer\n│       ├── Music        # jeppes musikfiler\n│       ├── Pictures     # jeppes billeder\n│       ├── Videos       # jeppes videofiler\n│       └── Projects     # Personlige kodeprojekter og scripts\n│           └── snake_game\n│               ├── main.py # Python-kode til et snake-spil\n│               └── assets  # Grafikfiler til spillet\n├── root                 # Superbrugerens hjemmemappe\n├── usr                  # Bruger- og systemprogrammer\n│   ├── bin              # Programmer installeret til brugere\n│   ├── lib              # Systemets biblioteker\n│   └── local            # Lokalt installerede programmer\n├── var                  # Variable data som logs og mails\n│   ├── log              # Systemets logfiler\n│   └── tmp              # Midlertidige filer\n├── tmp                  # Midlertidige filer (slettes ved genstart)\n├── dev                  # Systemets enheder som harddiske og terminaler\n├── mnt                  # Monteringspunkt for midlertidige enheder\n│   └── usb-drive        # En USB-nøgle monteret her\n└── media                # Monteringspunkt for eksterne enheder\n    └── jeppe-usb        # jeppes eksterne harddisk hvis monteret\n\n\n\nWindows\nC:\\\n├── Program Files            # Programmer installeret for alle brugere\n├── Program Files (x86)      # 32-bit versioner (på 64-bit systemer)\n├── Users                    # Brugermapper (til hver bruger på systemet)\n│   └── jeppe                # Brugeren \"jeppe\"'s hjemmemappe\n│       ├── Documents        # jeppes dokumenter\n│       ├── Downloads        # jeppes downloadede filer\n│       ├── Music            # jeppes musikfiler\n│       ├── Pictures         # jeppes billeder\n│       ├── Videos           # jeppes videofiler\n│       ├── Desktop          # Filer og genveje på jeppes skrivebord\n│       ├── AppData          # jeppes personlige app-data og indstillinger\n│       └── Projects         # Personlige kodeprojekter og scripts\n│           └── snake_game\n│               ├── main.py  # Python-kode til et snake-spil\n│               └── assets   # Grafikfiler til spillet\n├── Windows                  # Operativsystemets filer\n│   ├── System32             # Vigtige systemfiler \n│   └── Temp                 # Midlertidige filer, der bruges af systemet\n├── ProgramData              # Data, der deles af applikationer på systemet\n└── Temp                     # Midlertidige filer\n\n\n\n\nNavigation: Absolutte og relative stier\n\nAbsolut sti: En sti, der beskriver placeringen af en fil eller mappe i forhold til root-mappen. Fx /home/user/documents/projekt.docs eller C:\\Users\\Username\\Documents\\projekt.docx.\nRelativ sti: En sti, der beskriver placeringen af en fil eller mappe i forhold til den nuværende mappe. Hvis vi er i mappen /home/user, kan vi nøjes med den relative sti documents/projekt.docx for at henvise til filen.\n\n\n1ls\n     ls -l\n     ls -a\n\n2cd\n     cd ..\n     cd ~\n     cd -\n\n3touch filnavn.type\n\n4mkdir ny-mappe\n\n5rm filnavn.type\n\n6rm -r ny-mappe\n\n\n1\n\nLister filer og mapper i den aktuelle mappe. ls -l lister filer og mapper med detaljer (fx rettigheder, størrelse). ls -a viser alle filer, inklusiv skjulte filer.\n\n2\n\nSkifter til en anden mappe. cd .. går én mappe op/tilbage (til forældermappen). cd ~ går til brugerens hjemmemappe. cd - skifter tilbage til den seneste mappe, du var i.\n\n3\n\nOpretter en ny, tom fil med angivet navn og type.\n\n4\n\nOpretter en ny mappe med det angivne navn.\n\n5\n\nSletter en fil med det angivne navn.\n\n6\n\nSletter en mappe og alt indholdet i den rekursivt.\n\n\n\n\n\nEr navigation med CML nødvendigt? Nej. Men det kan give et flow, hvis vi primært laver kodearbejde da terminalen kan tilgås “indeni” programmer som Rstudio eller vscode. Men uanset om man bruger mus eller tastetur til at navigere på sin computer, er det vigtigt at vide, hvordan filer er organiseret, hvis man har en computer-baseret stilling."
  },
  {
    "objectID": "workshop/decomposition.html",
    "href": "workshop/decomposition.html",
    "title": "",
    "section": "",
    "text": "Decomposition"
  },
  {
    "objectID": "workshop/descriptive-stat.html",
    "href": "workshop/descriptive-stat.html",
    "title": "",
    "section": "",
    "text": "Lorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam pretium malesuada potenti commodo rutrum molestie tincidunt sodales. Risus nulla dui faucibus odio est phasellus tempus. Sollicitudin dapibus nunc ex congue nostra sapien velit. Praesent pellentesque vitae sociosqu orci magnis habitant maximus metus quisque. Velit tempus ad sodales hac; suspendisse suscipit.\n\n R packages Python imports\n\n\n\nlibrary(tidyverse)\n\n\n\n\nimport pandas as pd\nimport session_info\n\n\n\n\n\n R Python Session Info\n\n\n\nx &lt;- seq(1, 10)\n...\nplot(x, y)\n\n\n\n\n1+1\n\n\n\n\ndevtools::session_info(pkgs = \"attached\", info = c(\"platform\", \"packages\"))\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Copenhagen\n date     2024-11-04\n pandoc   3.3 @ /usr/local/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package   * version date (UTC) lib source\n dplyr     * 1.1.4   2023-11-17 [1] CRAN (R 4.2.0)\n forcats   * 1.0.0   2023-01-29 [1] CRAN (R 4.2.0)\n ggplot2   * 3.5.1   2024-04-23 [1] CRAN (R 4.2.1)\n lubridate * 1.9.3   2023-09-27 [1] CRAN (R 4.2.0)\n purrr     * 1.0.2   2023-08-10 [1] CRAN (R 4.2.0)\n readr     * 2.1.5   2024-01-10 [1] CRAN (R 4.2.1)\n stringr   * 1.5.1   2023-11-14 [1] CRAN (R 4.2.0)\n tibble    * 3.2.1   2023-03-20 [1] CRAN (R 4.2.0)\n tidyr     * 1.3.1   2024-01-24 [1] CRAN (R 4.2.1)\n tidyverse * 2.0.0   2023-02-22 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\nsession_info.show()\n\n-----\npandas              2.0.3\nsession_info        1.0.0\n-----\nPython 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:13:45) [Clang 14.0.6 ]\nmacOS-10.16-x86_64-i386-64bit\n-----\nSession information updated at 2024-11-04 13:51"
  },
  {
    "objectID": "workshop/sna-vna.html",
    "href": "workshop/sna-vna.html",
    "title": "",
    "section": "",
    "text": "Case: Social networks\n\n R packages Python\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(segregation)\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport session_info\n\n\n\n\n\n R Python Session Info\n\n\n\n1+1\n\n\n\n\nmat_friendship = pd.read_table(\"https://www.dropbox.com/s/0saiulir3pr566k/ELfriend.dat?dl=1\", delim_whitespace=True, header=None) \nmat_advice = pd.read_table(\"https://www.dropbox.com/s/apq42n1grim23k9/ELadv.dat?dl=1\", delim_whitespace=True, header=None) \nmat_work = pd.read_table(\"https://www.dropbox.com/s/dliz0sd7or8tv01/ELwork.dat?dl=1\", delim_whitespace=True, header=None)\n\n\n\n\ndevtools::session_info(pkgs = \"attached\", info = c(\"platform\", \"packages\"))\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Copenhagen\n date     2024-11-04\n pandoc   3.3 @ /usr/local/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.1.4   2023-11-17 [1] CRAN (R 4.2.0)\n forcats     * 1.0.0   2023-01-29 [1] CRAN (R 4.2.0)\n ggplot2     * 3.5.1   2024-04-23 [1] CRAN (R 4.2.1)\n lubridate   * 1.9.3   2023-09-27 [1] CRAN (R 4.2.0)\n purrr       * 1.0.2   2023-08-10 [1] CRAN (R 4.2.0)\n readr       * 2.1.5   2024-01-10 [1] CRAN (R 4.2.1)\n segregation * 1.1.0   2023-12-02 [1] CRAN (R 4.2.0)\n stringr     * 1.5.1   2023-11-14 [1] CRAN (R 4.2.0)\n tibble      * 3.2.1   2023-03-20 [1] CRAN (R 4.2.0)\n tidyr       * 1.3.1   2024-01-24 [1] CRAN (R 4.2.1)\n tidyverse   * 2.0.0   2023-02-22 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\nsession_info.show()\n\n-----\nnumpy               1.24.3\npandas              2.0.3\nsession_info        1.0.0\n-----\nPython 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:13:45) [Clang 14.0.6 ]\nmacOS-10.16-x86_64-i386-64bit\n-----\nSession information updated at 2024-11-04 13:54\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Visualizing the stylized population network\n\n\n\n\n\n\nsee figure in full screen"
  },
  {
    "objectID": "workshop/nlp.html",
    "href": "workshop/nlp.html",
    "title": "",
    "section": "",
    "text": "Hvad er NLP?\nNatural Language Processing (NLP) er et centralt felt indenfor AI (kunstig intellegens). Grundlæggende handler NLP om hvordan en computer kan forstå og fortolke naturligt sprog, dvs. menneskeligt talt sprog. Gerne opgaven er at maskiner kan bearbejde dette sprog (og endda kunne producere det).\nI dag spiller NLP en stor rolle i vores hverdag, da det påvirker den måde vi interagerer med teknologi og gør denne interaktion meget mere effektiv. Vi kan kun forvente at dette samspil, takket være NLP, fortsat blive mere effektivt og af større betydning i fremtiden.\n\nI kender allerede til NLP\nNLP er allerede dybt integreret i mange af de værktøjer og teknologier vi anvender eller bliver eksponeret til dagligt:\n\nSøgemaskinger: Google (og konkurrenter) bruger NLP til at forstå de input og returnere det du faktisk efterspørger. Det er derfor søgemaskiner i dag kan “overkomme” stavefejl, synonymer, kontekst specikke forespørgsler, osv.\nSiri, Alexa, Google Assistant: De lytter til os hele tiden, hvis først vi tænder for dem …\nOversættelser (mellem menneskelige sprog): Services som Google Translate oversætter ikke bare ord-for-ord men forstår sig også på forskelle i syntaks, grammatik og (sproglige) kontekster og konventioner.\nChatbots …\nSpamfiltrering: Som vi kommer til at lære i dag.\n\n\n\nEt oversættelsesperspektiv\nComputeren forstår ikke sprog på samme måde som mennesker gør. De kan læse 1 og de kan læse 0; men de kan sætte disse tegn sammen i uendelige rækker af varierende kompleksitet. Dvs. mønstre af binære numeriske inputs. NLP handler om at bygge bro mellem den måde, mennesker kommunikerer på, og hvordan maskiner forstår data.\nEn IKKE-UDTØMMENDE liste af grundlæggende elementer i oversættelse af naturligt sprog til maskin-læsbart sprog:\n\nTokenization, som handler om at dele en tekst op i mindre dele, ofte ord eller sætninger. En sætning som “Jeg elsker data!” blive delt op i tre(fire) tokens: [“Jeg”, “elsker”, “data”, “!”].\nStemming og Lemmatization, som reducerer ord til deres grundform. Fx bliver “løbende” og “løber” reduceret til roden, “løb”.\nPart-of-Speech Tagging (POS Tagging), som identificerer ordklasser (som verber, substantiver osv.) for hvert ord i en sætning, hvilket gør det muligt at forstå ordenes funktion i sætningen.\nNamed Entity Recognition (NER), som identificerer navne på personer, steder eller organisationer i en tekst. For eksempel i sætningen “Aalborg Universitet er et universitet i Danmark” vil “Aalborg Universitet” blive genkendt som en organisation og “Danmark” som et land.\n\nDette oversættelsesperspektiv i en digital kontekst er centralt i dagens workshop.\n\n\n\nCase: find Elon\n\n R packages Python\n\n\n\nlibrary(tidytext)\n\n\n\n\nimport numpy as np\nimport session_info\n\n\n\n\n\n R Python sessionInfo()\n\n\n\nsuppressMessages(tweets &lt;- vroom(\"find_elon\"))\n\nelon_tweet_df &lt;- \n  tibble(tweets) %&gt;% \n  rename(real = `1`,\n         text = `0`) %&gt;% \n  mutate(real = as_factor(if_else(real == \"1\", \"real_elon\", \"fake_elon\"))) %&gt;% \n  mutate(tweet_id = as_factor(row_number())) \n  \n\nelon_tweet_df %&gt;% head(10) %&gt;% gt()\n\n\n\n\n1+1\n\n\n\n\ndevtools::session_info(pkgs = \"attached\", info = c(\"platform\", \"packages\"))\n\nWarning in info != \"auto\" && info != \"all\": 'length(x) = 2 &gt; 1' in coercion to\n'logical(1)'\n\nWarning in info != \"auto\" && info != \"all\": 'length(x) = 2 &gt; 1' in coercion to\n'logical(1)'\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Copenhagen\n date     2024-11-04\n pandoc   3.3 @ /usr/local/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package  * version date (UTC) lib source\n tidytext * 0.4.2   2024-04-10 [1] CRAN (R 4.2.1)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\nsession_info.show()\n\n-----\nnumpy               1.24.3\nsession_info        1.0.0\n-----\nPython 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:13:45) [Clang 14.0.6 ]\nmacOS-10.16-x86_64-i386-64bit\n-----\nSession information updated at 2024-11-04 13:56"
  },
  {
    "objectID": "workshop/ml-exp.html",
    "href": "workshop/ml-exp.html",
    "title": "",
    "section": "",
    "text": "Case\n\n\nClustering\nThe aim of the analysis is to formulate a framework to meaningfully divide the school landscape into clusters based on grade-based scores and hold these grade-based clusters up against demographic characteristics of the schools. Thus, the aim of the analysis is to categorize schools based on performance in an exploratory framework, which later will be used in further descriptions of the school landscape.\nIn clustering analysis, the ‘distance’ between people is defined as the Euclidean distance. The euclidean distance is the shortest path between two point in space (i.e. a straight line). Most often, Euclidean^2 (L^2) is used.\n\n\\begin{aligned}\nd(\\mathbf{p}, \\mathbf{q}) = d(\\mathbf{q}, \\mathbf{p}) &= \\sqrt{ (q_{1}-p_{1})^2 + (q_{2}-p_{2})^2 + \\cdots +  (q_{n}-p_{n})^2 } \\\\\n&= \\sqrt{ \\sum_{i=1}^{n} (q_{i}-p_{i})^2}\n\\end{aligned}\n\nThere are many merging/linking rules in hierarchical clustering methods – from k-means to Ward’s. We’ll be using Ward’s method for this task for hierarchical clustering.\n\nIn Python, we use the de-facto standard; Pandas.\nIn R, we use the Rstudio standard rather than the classic R dataframe; tibbles.\n\n\n R Python sessionInfo()\n\n\n\ndf &lt;- vroom(\"wiz-schools_231121.tsv\")\n\n# Printing all columns and 10 rows\nhead(df) %&gt;% gt()\n\n\n\n\ndata = pd.read_csv(\"wiz-schools_231121.tsv\", sep='\\t')\n\n# Printing first 6 columns and first 10 rows of data\nprint(data.iloc[0:10, :])\n\n\n\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11       lattice_0.22-5    png_0.1-8         digest_0.6.33    \n [5] grid_4.2.1        jsonlite_1.8.8    evaluate_1.0.1    rlang_1.1.2      \n [9] cli_3.6.2         rstudioapi_0.15.0 Matrix_1.5-3      reticulate_1.34.0\n[13] rmarkdown_2.28    tools_4.2.1       htmlwidgets_1.6.4 xfun_0.41        \n[17] yaml_2.3.8        fastmap_1.1.1     compiler_4.2.1    htmltools_0.5.7  \n[21] knitr_1.45       \n\n\n\n\n\n\nClean data"
  },
  {
    "objectID": "workshop/regression.html",
    "href": "workshop/regression.html",
    "title": "",
    "section": "",
    "text": "Regression\n\nData …"
  },
  {
    "objectID": "workshop/plaintext.html",
    "href": "workshop/plaintext.html",
    "title": "",
    "section": "",
    "text": "Plain text"
  },
  {
    "objectID": "projects/mncontact.html",
    "href": "projects/mncontact.html",
    "title": "",
    "section": "",
    "text": "Majority and Minority Exposure in Childhood\n\nLorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam pretium malesuada potenti commodo rutrum molestie tincidunt sodales. Risus nulla dui faucibus odio est phasellus tempus. Sollicitudin dapibus nunc ex congue nostra sapien velit. Praesent pellentesque vitae sociosqu orci magnis habitant maximus metus quisque. Velit tempus ad sodales hac; suspendisse suscipit. Faucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem. Himenaeos adipiscing ultrices ex; rutrum dignissim turpis. Lorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam a. SKAL IKKE VÆRE LÆNGERE END DETTE.\nInteger habitant varius hendrerit torquent sodales. Fusce consectetur consectetur bibendum mattis justo aenean mauris nam sed. Potenti vel a; cubilia turpis porta faucibus donec. Luctus tempor feugiat elit ligula mollis. Efficitur risus consectetur tellus cras in scelerisque. Tincidunt faucibus convallis neque elit, potenti purus ac convallis. Luctus pharetra condimentum per vitae blandit eleifend ac condimentum. Arcu arcu ut ullamcorper class semper.\nHac magna eros fermentum vitae aliquet nisi mauris. Tortor id diam tortor magna nunc est nisi feugiat hac. Sit nunc cras duis primis sollicitudin aenean penatibus commodo. Porttitor netus facilisi per class lorem nibh. Finibus ultricies penatibus; mauris justo feugiat himenaeos sapien maximus. Facilisis habitasse nibh eu augue nisi tincidunt elit suspendisse. Nam molestie netus ex nullam in. Feugiat magna blandit quisque feugiat curabitur himenaeos convallis accumsan. Turpis aliquam quis dictumst quam; ultricies commodo consectetur."
  },
  {
    "objectID": "projects/direk.html",
    "href": "projects/direk.html",
    "title": "",
    "section": "",
    "text": "Diversity at management and employee levels and its implications for future recruitment\nLorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam pretium malesuada potenti commodo rutrum molestie tincidunt sodales. Risus nulla dui faucibus odio est phasellus tempus. Sollicitudin dapibus nunc ex congue nostra sapien velit. Praesent pellentesque vitae sociosqu orci magnis habitant maximus metus quisque. Velit tempus ad sodales hac; suspendisse suscipit.\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem. Himenaeos adipiscing ultrices ex; rutrum dignissim turpis. Libero sociosqu lacinia nibh; potenti elit viverra. Senectus fames fringilla praesent nascetur lacus lobortis dui tortor. Felis ridiculus lorem senectus convallis conubia nec phasellus nisi. Potenti sodales rhoncus et penatibus auctor morbi erat augue iaculis. Egestas dictumst phasellus class nec facilisis sapien lectus maximus iaculis. Quam nascetur fusce vivamus proin dolor; magna tempus curae."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Research",
    "section": "",
    "text": "Lorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam pretium malesuada potenti commodo rutrum molestie tincidunt sodales. Risus nulla dui faucibus odio est phasellus tempus. Sollicitudin dapibus nunc ex congue nostra sapien velit. Praesent pellentesque vitae sociosqu orci magnis habitant maximus metus quisque. Velit tempus ad sodales hac; suspendisse suscipit.\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem. Himenaeos adipiscing ultrices ex; rutrum dignissim turpis. Libero sociosqu lacinia nibh; potenti elit viverra. Senectus fames fringilla praesent nascetur lacus lobortis dui tortor. Felis ridiculus lorem senectus convallis conubia nec phasellus nisi. Potenti sodales rhoncus et penatibus auctor morbi erat augue iaculis. Egestas dictumst phasellus class nec facilisis sapien lectus maximus iaculis. Quam nascetur fusce vivamus proin dolor; magna tempus curae.\n\n\nHi! I’m a side note!\n\n\n\n\nDIREK\n\nDiversity at management and employee levels and its implications for future recruitment\nLorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam pretium malesuada potenti commodo rutrum molestie tincidunt sodales. Risus nulla dui faucibus odio est phasellus tempus. Sollicitudin dapibus nunc ex congue nostra sapien velit. Praesent pellentesque vitae sociosqu orci magnis habitant maximus metus quisque. Velit tempus ad sodales hac; suspendisse suscipit.\nFaucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem. Himenaeos adipiscing ultrices ex; rutrum dignissim turpis. Libero sociosqu lacinia nibh; potenti elit viverra. Senectus fames fringilla praesent nascetur lacus lobortis dui tortor. Felis ridiculus lorem senectus convallis conubia nec phasellus nisi. Potenti sodales rhoncus et penatibus auctor morbi erat augue iaculis. Egestas dictumst phasellus class nec facilisis sapien lectus maximus iaculis. Quam nascetur fusce vivamus proin dolor; magna tempus curae.\n\n\n\n\n\n\nMNcontact\n\nMajority and Minority Exposure in Childhood\n\n\n\n\n\n\nLorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam pretium malesuada potenti commodo rutrum molestie tincidunt sodales. Risus nulla dui faucibus odio est phasellus tempus. Sollicitudin dapibus nunc ex congue nostra sapien velit. Praesent pellentesque vitae sociosqu orci magnis habitant maximus metus quisque. Velit tempus ad sodales hac; suspendisse suscipit. Faucibus accumsan ipsum et tempor fringilla placerat nisl ultrices. Suscipit dignissim finibus platea efficitur inceptos consequat orci sem. Himenaeos adipiscing ultrices ex; rutrum dignissim turpis. Lorem ipsum odor amet, consectetuer adipiscing elit. Quam nullam a. SKAL IKKE VÆRE LÆNGERE END DETTE.\n\n\nInteger habitant varius hendrerit torquent sodales. Fusce consectetur consectetur bibendum mattis justo aenean mauris nam sed. Potenti vel a; cubilia turpis porta faucibus donec. Luctus tempor feugiat elit ligula mollis. Efficitur risus consectetur tellus cras in scelerisque. Tincidunt faucibus convallis neque elit, potenti purus ac convallis. Luctus pharetra condimentum per vitae blandit eleifend ac condimentum. Arcu arcu ut ullamcorper class semper.\nHac magna eros fermentum vitae aliquet nisi mauris. Tortor id diam tortor magna nunc est nisi feugiat hac. Sit nunc cras duis primis sollicitudin aenean penatibus commodo. Porttitor netus facilisi per class lorem nibh. Finibus ultricies penatibus; mauris justo feugiat himenaeos sapien maximus. Facilisis habitasse nibh eu augue nisi tincidunt elit suspendisse. Nam molestie netus ex nullam in. Feugiat magna blandit quisque feugiat curabitur himenaeos convallis accumsan. Turpis aliquam quis dictumst quam; ultricies commodo consectetur."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Larsen1, J. F.. Majority and Minority Exposure in Childhood: Studies of ethnic segregation in early life in Denmark and its consequences. Aalborg University Open Publishing. https://doi.org/10.54337/aau715499670\n\n  pdf    Publisher's Site \n\n\n\nLarsen1, J. F., & Larsen, C. A, (2023). Integration through Crossing Circles: Natives’ opportunity pools and diversification of friendships in a transforming Europe. Journal of Ethnic and Migration Studies, 50(12). https://doi.org/10.1080/1369183X.2023.2178396\n\n  Publisher's Site \n\n\n\nLarsen1, J. F., & Larsen, C. A, (2022). Herkomst blandt 0 – 16-årige bosat i Danmark: Stigende etnisk diversitet og koncentration fra 1985 til 2019. Metode & Forskningsdesign, (4), 47-68. https://doi.org/10.54337/ojs.mf.2022.4.7595\n\n  pdf    Publisher's Site \n\n\n\n1 Since publication, I have gotten married and taken my wife’s name. So I was once a Larsen, but today I am a Qvist."
  }
]